{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk import ngrams\n",
    "import itertools\n",
    "import os\n",
    "from random import randint\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(driver, url): # Hàm mở url \n",
    "    driver.get(url)\n",
    "\n",
    "    WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[id=\"root\"]')))\n",
    "\n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "\n",
    "    for i in range(1, total_height, 2):\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "\n",
    "    check_total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    if check_total_height > total_height:\n",
    "        for i in range(total_height, check_total_height, 2):\n",
    "            driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_product(driver, keyword): # Tìm url sản phẩm theo keyword\n",
    "    keyword = keyword.lower()\n",
    "\n",
    "    url = 'https://www.lazada.vn/tag/%s//?service=official'%('-'.join(keyword.split(' ')))\n",
    "    get_url(driver, url)\n",
    "\n",
    "    element= WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-qa-locator=\"general-products\"]')))\n",
    "    html_of_interest=driver.execute_script('return arguments[0].innerHTML',element)\n",
    "    soup = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "    raw_links = soup.select('div[data-qa-locator=\"product-item\"] > div > div > div > div > a')[::2]\n",
    "    list_links = []\n",
    "\n",
    "    for num_link in range(len(raw_links)):\n",
    "        dict_links = {}\n",
    "\n",
    "        # Url của sản phẩm\n",
    "        link = raw_links[num_link].attrs['href']\n",
    "        dict_links['url'] = 'https:' + link\n",
    "        \n",
    "        # Tên sản phẩm\n",
    "        dict_links['Product name'] = soup.select('div[data-qa-locator=\"product-item\"] > div > div > div > div > a > div > img')[num_link].attrs['alt']\n",
    "\n",
    "        # Số lượng bán\n",
    "        check_sold = soup.select('div[data-qa-locator=\"product-item\"] > div > div > div > div[class=\"_6uN7R\"]')[num_link].select('span > span:not([class])')\n",
    "        if check_sold != []:\n",
    "            dict_links['Product sold'] = check_sold[0].text.replace(' Đã bán', '').replace(',', '')\n",
    "        else:\n",
    "            dict_links['Product sold'] = 0\n",
    "\n",
    "        list_links.append(dict_links)\n",
    "\n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text): # Hàm tiền xử lí dữ liệu string và trả về 1 string\n",
    "    # Chữ hoa thành chữ thường\n",
    "    pre_text = text.lower()\n",
    "\n",
    "    # Loại bỏ dấu câu\n",
    "    for c in punctuation:\n",
    "        pre_text= pre_text.replace(c,' ')\n",
    "    \n",
    "    pre_text = \" \".join(pre_text.split())\n",
    "\n",
    "    return pre_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lọc sản phẩm không liên quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accessory(list_links, keyword): # Hàm loại bỏ sản phẩm phụ kiện (ốp, bao da, kính cường lực) và trả về 1 list\n",
    "    # Xóa tên thương hiệu trong Tên sản phẩm\n",
    "    brand = pd.read_csv(r'..\\smartphones.csv')[['brand_name', 'model']]\n",
    "\n",
    "    for link in list_links:\n",
    "        text = link['Product name']\n",
    "        extract_test = extract_similar_keywords(preprocessing(text), keyword)\n",
    "\n",
    "        for ex in extract_test:\n",
    "            check_product = list(brand[brand['model'].apply(lambda x: x.lower()) == ex].values)\n",
    "            if check_product != []:\n",
    "                check_brand = list(brand[brand['model'].apply(lambda x: x.lower()) == ex].values[0])[0].lower()\n",
    "                link['Product name'] = text.lower().replace(check_brand, '')\n",
    "\n",
    "\n",
    "    with open(r'..\\accessory_keyword.txt', encoding='utf-8') as f:\n",
    "        accessory_keyword = f.read().splitlines()\n",
    "\n",
    "    # Loại bỏ từ khóa chứa trong accessory_keyword\n",
    "    exclude_links = []\n",
    "\n",
    "    for link in list_links:\n",
    "        for acc_kw in accessory_keyword:\n",
    "            if acc_kw in link['Product name'].lower():\n",
    "                exclude_links.append(link)\n",
    "\n",
    "    list_links = [link for link in list_links if link not in exclude_links]\n",
    "\n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_similar_keywords(text, keyword): # Hàm trích xuất từ khóa liên quan đến keyword trong text và trả về 1 list\n",
    "    smartphone_name = pd.read_csv('..\\smartphones.csv')['model']\n",
    "    similar_keywords_list = [name.lower() for name in smartphone_name if keyword in name.lower()]\n",
    "    extracted_keyword_list = []\n",
    "    main_topic_keyword_list = []\n",
    "\n",
    "    for similar_keyword in similar_keywords_list:\n",
    "        keyword_ngram_list = []\n",
    "        for n in range(2, len(similar_keyword)):\n",
    "            n_gram = ngrams(similar_keyword.split(), n)\n",
    "\n",
    "            for grams in n_gram:\n",
    "                keyword_ngram_list.append(list(grams))    \n",
    "\n",
    "        for keyword_ngram in keyword_ngram_list:\n",
    "            tokenizer = MWETokenizer()\n",
    "            tokenizer.add_mwe(keyword_ngram)\n",
    "            phrase_list = tokenizer.tokenize(text.split())\n",
    "\n",
    "            topic_keyword = '_'.join(keyword_ngram)\n",
    "            if topic_keyword in phrase_list:\n",
    "                extracted_keyword_list.append(keyword_ngram)\n",
    "\n",
    "    extracted_keyword_list.sort()\n",
    "    extracted_keyword_list = list(l for l,_ in itertools.groupby(extracted_keyword_list))\n",
    "\n",
    "    freq_extracted_keyword = {}\n",
    "\n",
    "    for l,_ in itertools.groupby(extracted_keyword_list):\n",
    "        kw = ' '.join(l)\n",
    "        freq_extracted_keyword[kw] = text.count(kw)\n",
    "\n",
    "    freq_extracted_keyword = sorted(list(freq_extracted_keyword.items()), key = lambda key : len(key[0]), reverse=True)\n",
    "    freq_extracted_keyword = {ele[0] : ele[1]  for ele in freq_extracted_keyword}\n",
    "\n",
    "    freq_key_list = list(freq_extracted_keyword.keys())\n",
    "    check_freq_dict = freq_extracted_keyword.copy()\n",
    "\n",
    "    for key in freq_key_list:\n",
    "        req = freq_extracted_keyword[key]\n",
    "\n",
    "        for check_key in freq_key_list:\n",
    "            if (key != check_key) and (key in check_key) and (check_freq_dict[check_key] > 0):\n",
    "                check_freq_dict[key] -= 1\n",
    "\n",
    "    for key, value in check_freq_dict.items():\n",
    "        if value > 0:\n",
    "            main_topic_keyword_list.append(key)\n",
    "    \n",
    "    return main_topic_keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_links(list_links, keyword): # Hàm loại bỏ accessory, trích xuất url của sản phẩm keyword và trả về 1 list\n",
    "    filter_video_url = []\n",
    "\n",
    "    # Loại bỏ accessory\n",
    "    list_links = remove_accessory(list_links, keyword)\n",
    "\n",
    "    for link in list_links:\n",
    "        product_name = link['Product name']\n",
    "\n",
    "        pre_text = preprocessing(product_name)\n",
    "\n",
    "        similar_keywords = extract_similar_keywords(pre_text, keyword)\n",
    "\n",
    "        if keyword in similar_keywords:\n",
    "            filter_video_url.append(link)\n",
    "\n",
    "    return filter_video_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lấy thông tin và reviews sản phẩm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(driver, url=None): # Hàm lấy code html của url và trả về soup\n",
    "    if url != None:\n",
    "        get_url(driver, url)\n",
    "    \n",
    "    driver.implicitly_wait(30)\n",
    "    element= WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[id=\"root\"]')))\n",
    "    html_of_interest=driver.execute_script('return arguments[0].innerHTML',element)\n",
    "    soup = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_info(soup, sold): # Hàm trả về 1 dict thông tin sản phẩm từ soup\n",
    "    dict_product_info = {}\n",
    "\n",
    "    # Tên sản phẩm\n",
    "    dict_product_info['Name'] = soup.select('h1[class=\"pdp-mod-product-badge-title\"]')[0].text\n",
    "\n",
    "    # Thương hiệu\n",
    "    dict_product_info['Brand'] = soup.select('div[class=\"pdp-product-brand\"] > a')[0].text\n",
    "\n",
    "    # Check lượt đánh giá\n",
    "    review_count = soup.select('div[class=\"pdp-review-summary\"] > a')[0].text\n",
    "    if review_count != 'No Ratings':\n",
    "        # Số lượt đánh giá\n",
    "        dict_product_info['Reviews count'] = review_count\n",
    "\n",
    "        # Đánh giá sao\n",
    "        dict_product_info['Star rating'] = soup.select('span[class=\"score-average\"]')[0].text\n",
    "    else:\n",
    "        dict_product_info['Reviews count'] = 0\n",
    "\n",
    "    # Số lượng bán\n",
    "    dict_product_info['Quantity'] = sold\n",
    "\n",
    "    # Giá bán\n",
    "    dict_product_info['Price'] = soup.select('div[class=\"pdp-product-price\"] > span')[0].text.replace('₫', '').replace('.', '').strip()\n",
    "\n",
    "    # Ngày crawl\n",
    "    dict_product_info['Crawl date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Thông số lựa chọn (Màu sắc, dung lượng,...)\n",
    "    list_option_label = soup.select('div[class=\"sku-selector\"] > div')\n",
    "    if list_option_label != []:\n",
    "        for option_label in list_option_label:\n",
    "            list_option = option_label.select('div > div > div[class=\"sku-prop-content\"] > span')\n",
    "            list_all_option = []\n",
    "\n",
    "            for option in list_option:\n",
    "                list_all_option.append(option.text)\n",
    "\n",
    "            dict_product_info[option_label.select('div > h6')[0].text] = ', '.join(list_all_option)\n",
    "\n",
    "    # Tên shop\n",
    "    dict_product_info['Shop name'] = soup.select('div[class=\"seller-name__detail\"] > a')[0].text\n",
    "\n",
    "    # Đánh giá shop\n",
    "    check_shop_rating = soup.select('div[class=\"seller-info-value rating-positive\"]')\n",
    "    if check_shop_rating != []:\n",
    "        dict_product_info['Shop rating'] = check_shop_rating[0].text\n",
    "    else:\n",
    "        dict_product_info['Shop rating'] = 'Không có đánh giá'\n",
    "\n",
    "    # Thông số kỹ thuật\n",
    "    list_specification = soup.select('div[class=\"pdp-general-features\"] > ul >li')\n",
    "    for s in list_specification:\n",
    "        name = s.select('span')[0].text.strip()\n",
    "        dict_product_info[name] = s.select('div')[0].text\n",
    "\n",
    "    # Mô tả sản phẩm\n",
    "    dict_product_info['Describe'] = soup.select('div[class=\"html-content detail-content\"]')[0].text\n",
    "\n",
    "    return dict_product_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(driver): # Hàm trả về 1 list reviews sản phẩm\n",
    "    all_reviews = []\n",
    "    soup = get_soup(driver)\n",
    "    shop_name = soup.select('div[class=\"seller-name__detail\"] > a')[0].text\n",
    "    check_reviews = soup.select('div[class=\"mod-empty\"]')\n",
    "\n",
    "    if check_reviews == []:\n",
    "        filter_btn = driver.find_element(By.CSS_SELECTOR,'span[class=\"condition\"]')\n",
    "        sleep(randint(20, 25))\n",
    "        driver.execute_script(\"arguments[0].click();\", filter_btn)\n",
    "        filter_star = driver.find_elements(By.CSS_SELECTOR,'li[class=\"next-menu-item\"]')[1:]\n",
    "\n",
    "        for star_num in range(1, len(filter_star) + 1):\n",
    "            driver.execute_script(\"arguments[0].click();\", filter_btn)\n",
    "            star = driver.find_elements(By.CSS_SELECTOR,'li[class=\"next-menu-item\"]')[star_num]\n",
    "            \n",
    "            driver.execute_script(\"arguments[0].click();\", star)\n",
    "            sleep(randint(20, 25))\n",
    "            soup = get_soup(driver)\n",
    "            try:\n",
    "                last_page = int(soup.select('div[class=\"next-pagination-list\"] > button')[-1].text)\n",
    "            except:\n",
    "                last_page = 1\n",
    "            for page_num in range(last_page):\n",
    "                # Lấy thông tin review\n",
    "                list_review = soup.select('div[class=\"mod-reviews\"] > div')\n",
    "\n",
    "                for review in list_review:\n",
    "                    dict_review = {}\n",
    "\n",
    "                    # Tên shop\n",
    "                    dict_review['Shop name'] = shop_name\n",
    "\n",
    "                    # Tên\n",
    "                    dict_review['Reviewer name'] = review.select('div[class=\"middle\"] > span')[0].text\n",
    "\n",
    "                    # Nội dung\n",
    "                    dict_review['Content'] = review.select('div > div[class=\"content\"]')[0].text\n",
    "\n",
    "                    # Đánh giá\n",
    "                    list_star = review.select('div[class=\"top\"] > div > img')\n",
    "                    rating_score = 0\n",
    "\n",
    "                    for star in list_star:\n",
    "                        if star.attrs['src'] == '//laz-img-cdn.alicdn.com/tfs/TB19ZvEgfDH8KJjy1XcXXcpdXXa-64-64.png':\n",
    "                            rating_score += 1\n",
    "\n",
    "                    dict_review['Rating'] = rating_score\n",
    "\n",
    "                    # Thời gian đánh giá\n",
    "                    dict_review['Rating date'] = review.select('div[class=\"top\"] > span')[0].text\n",
    "\n",
    "                    # Crawl date\n",
    "                    dict_review['Crawl date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "                    all_reviews.append(dict_review)\n",
    "\n",
    "                # Bấm chuyển page\n",
    "                try:\n",
    "                    nexr_page_btn = driver.find_element(By.CSS_SELECTOR, 'button[class=\"next-btn next-btn-normal next-btn-medium next-pagination-item next\"]')\n",
    "                    driver.execute_script(\"arguments[0].click();\", nexr_page_btn)\n",
    "                    sleep(30)\n",
    "                except:\n",
    "                    break\n",
    "                # Lấy soup mới\n",
    "                soup = get_soup(driver)\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lưu file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(list_of_dict, folder_path, file_name):\n",
    "    save_loc = r'%s%s.csv'%(folder_path, file_name)\n",
    "    exist_file = os.path.exists(save_loc)\n",
    "\n",
    "    if not exist_file:\n",
    "        df = pd.DataFrame(list_of_dict)\n",
    "        df.to_csv(save_loc, index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(save_loc)\n",
    "        df_new = pd.DataFrame(list_of_dict)\n",
    "        concat_file = pd.concat([df, df_new], ignore_index = True)\n",
    "\n",
    "        concat_file.to_csv(save_loc, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "user_agent = ua.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mở trình duyệt Google Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito') # Tab ẩn danh\n",
    "options.add_argument(\"--start-maximized\") # Full window\n",
    "# options.add_argument('headless') # Không hiển thị chrome\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "# options.add_argument('--proxy-server=%s'%PROXY)\n",
    "s = Service('../chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=s, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhập keyword (tên sản phẩm cần tìm kiếm)\n",
    "keyword = input('Keyword: ')\n",
    "\n",
    "# Tìm sản phẩm dựa vào keyword\n",
    "list_links = search_product(driver, keyword)\n",
    "\n",
    "# Lọc sản phẩm không liên quan và trích xuất url\n",
    "filter_url_list = filter_links(list_links, keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info = []\n",
    "product_reviews = []\n",
    "\n",
    "for product_url in filter_url_list:\n",
    "    product_soup = get_soup(driver, url=product_url['url'])\n",
    "\n",
    "    product_info.append(get_product_info(product_soup, sold=product_url['Product sold']))\n",
    "    \n",
    "    product_reviews = product_reviews + get_review(driver)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"..\\..\\Data\\Lazada\\\\\"\n",
    "\n",
    "# Lưu file product_info\n",
    "# file_name_info = '%s_info'%('_'.join(keyword.split(' ')))\n",
    "# save_csv(product_info, folder_path, file_name_info)\n",
    "\n",
    "# Lưu file reviews\n",
    "file_name_reviews = '%s_reviews'%('_'.join(keyword.split(' ')))\n",
    "save_csv(product_reviews, folder_path, file_name_reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
