{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk import ngrams\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tìm url theo keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_product(driver, keyword): # Tìm url sản phẩm theo keyword\n",
    "    keyword = keyword.lower()\n",
    "\n",
    "    url = 'https://tiki.vn/search?q=%s'%('%20'.join(keyword.split(' ')))\n",
    "    driver.get(url)\n",
    "    sleep(3)\n",
    "\n",
    "    element= WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div[class=\"CatalogProducts__Wrapper-sc-1r8ct7c-0 fKlIZg\"]')))\n",
    "    html_of_interest=driver.execute_script('return arguments[0].innerHTML',element)\n",
    "    soup = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "    raw_links = soup.select('a[data-view-id=\"product_list_item\"]')\n",
    "    list_links = []\n",
    "\n",
    "    for num_link in range(len(raw_links)):\n",
    "        dict_links = {}\n",
    "\n",
    "        # Url của sản phẩm\n",
    "        link = raw_links[num_link].attrs['href']\n",
    "        if 'tka.tiki.vn' in link:\n",
    "            dict_links['url'] = 'https:' + link\n",
    "        else:\n",
    "            dict_links['url'] = 'https://tiki.vn' + link\n",
    "        \n",
    "        # Tên sản phẩm\n",
    "        dict_links['Product name'] = soup.select('h3[class=\"style__NameStyled-sc-2j4n5s-8 juFQqr product-name\"]')[num_link].text\n",
    "\n",
    "        # Brand\n",
    "        dict_links['Brand'] = soup.select('div[class=\"style__AboveProductNameStyled-sc-m30gte-0 hjPFIz above-product-name-info\"] > span')[num_link].text\n",
    "\n",
    "        list_links.append(dict_links)\n",
    "\n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text): # Hàm tiền xử lí dữ liệu string và trả về 1 string\n",
    "    # Chữ hoa thành chữ thường\n",
    "    pre_text = text.lower()\n",
    "\n",
    "    # Loại bỏ dấu câu\n",
    "    for c in punctuation:\n",
    "        pre_text= pre_text.replace(c,' ')\n",
    "    \n",
    "    pre_text = \" \".join(pre_text.split())\n",
    "\n",
    "    return pre_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lọc sản phẩm không liên quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accessory(list_links): # Hàm loại bỏ sản phẩm phụ kiện (ốp, bao da, kính cường lực) và trả về 1 list\n",
    "    # Xóa tên thương hiệu trong Tên sản phẩm\n",
    "    for link in list_links:\n",
    "        split_link = link['Product name'].split(' ')\n",
    "        split_test = link['Product name'].lower().split(' ')\n",
    "        brand = link['Brand'].lower()\n",
    "        if brand in split_test:\n",
    "            brand_index = split_test.index(brand)\n",
    "            split_link.pop(brand_index)\n",
    "            link['Product name'] = ' '.join(split_link)\n",
    "\n",
    "    with open(r'..\\accessory_keyword.txt', encoding='utf-8') as f:\n",
    "        accessory_keyword = f.read().splitlines()\n",
    "\n",
    "    # Loại bỏ từ khóa chứa trong accessory_keyword\n",
    "    exclude_links = []\n",
    "\n",
    "    for link in list_links:\n",
    "        for acc_kw in accessory_keyword:\n",
    "            if acc_kw in link['Product name'].lower():\n",
    "                exclude_links.append(link)\n",
    "\n",
    "    list_links = [link for link in list_links if link not in exclude_links]\n",
    "\n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_similar_keywords(text, keyword): # Hàm trích xuất từ khóa liên quan đến keyword trong text và trả về 1 list\n",
    "    smartphone_name = pd.read_csv('..\\smartphones.csv')['model']\n",
    "    similar_keywords_list = [name.lower() for name in smartphone_name if keyword in name.lower()]\n",
    "    extracted_keyword_list = []\n",
    "    main_topic_keyword_list = []\n",
    "\n",
    "    for similar_keyword in similar_keywords_list:\n",
    "        keyword_ngram_list = []\n",
    "        for n in range(2, len(similar_keyword)):\n",
    "            n_gram = ngrams(similar_keyword.split(), n)\n",
    "\n",
    "            for grams in n_gram:\n",
    "                keyword_ngram_list.append(list(grams))    \n",
    "\n",
    "        for keyword_ngram in keyword_ngram_list:\n",
    "            tokenizer = MWETokenizer()\n",
    "            tokenizer.add_mwe(keyword_ngram)\n",
    "            phrase_list = tokenizer.tokenize(text.split())\n",
    "\n",
    "            topic_keyword = '_'.join(keyword_ngram)\n",
    "            if topic_keyword in phrase_list:\n",
    "                extracted_keyword_list.append(keyword_ngram)\n",
    "\n",
    "    extracted_keyword_list.sort()\n",
    "    extracted_keyword_list = list(l for l,_ in itertools.groupby(extracted_keyword_list))\n",
    "\n",
    "    freq_extracted_keyword = {}\n",
    "\n",
    "    for l,_ in itertools.groupby(extracted_keyword_list):\n",
    "        kw = ' '.join(l)\n",
    "        freq_extracted_keyword[kw] = text.count(kw)\n",
    "\n",
    "    freq_extracted_keyword = sorted(list(freq_extracted_keyword.items()), key = lambda key : len(key[0]), reverse=True)\n",
    "    freq_extracted_keyword = {ele[0] : ele[1]  for ele in freq_extracted_keyword}\n",
    "\n",
    "    freq_key_list = list(freq_extracted_keyword.keys())\n",
    "    check_freq_dict = freq_extracted_keyword.copy()\n",
    "\n",
    "    for key in freq_key_list:\n",
    "        req = freq_extracted_keyword[key]\n",
    "\n",
    "        for check_key in freq_key_list:\n",
    "            if (key != check_key) and (key in check_key) and (check_freq_dict[check_key] > 0):\n",
    "                check_freq_dict[key] -= 1\n",
    "\n",
    "    for key, value in check_freq_dict.items():\n",
    "        if value > 0:\n",
    "            main_topic_keyword_list.append(key)\n",
    "    \n",
    "    return main_topic_keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_links(list_links, keyword): # Hàm loại bỏ accessory, trích xuất url của sản phẩm keyword và trả về 1 list\n",
    "    filter_video_url = []\n",
    "\n",
    "    # Loại bỏ accessory\n",
    "    list_links = remove_accessory(list_links)\n",
    "\n",
    "    for link in list_links:\n",
    "        product_name = link['Product name']\n",
    "\n",
    "        pre_text = preprocessing(product_name)\n",
    "\n",
    "        similar_keywords = extract_similar_keywords(pre_text, keyword)\n",
    "\n",
    "        if keyword in similar_keywords:\n",
    "            filter_video_url.append(link['url'])\n",
    "\n",
    "    return filter_video_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lấy thông tin và reviews sản phẩm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(driver, url): # Hàm mở url \n",
    "    driver.get(url)\n",
    "\n",
    "    WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'main')))\n",
    "\n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "\n",
    "    for i in range(1, total_height, 5):\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "\n",
    "    check_total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    if check_total_height > total_height:\n",
    "        for i in range(total_height, check_total_height, 5):\n",
    "            driver.execute_script(\"window.scrollTo(0, {});\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(driver, url=None): # Hàm lấy code html của url và trả về soup\n",
    "    if url != None:\n",
    "        get_url(driver, url)\n",
    "\n",
    "    element= WebDriverWait(driver, 60).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'main > div[class=\"ContainerRevamp-sc-1hvvgwz-0 dOGdaN\"]')))\n",
    "    html_of_interest=driver.execute_script('return arguments[0].innerHTML',element)\n",
    "    soup = BeautifulSoup(html_of_interest, 'lxml')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_info(soup): # Hàm trả về 1 dict thông tin sản phẩm từ soup\n",
    "    dict_product_info = {}\n",
    "\n",
    "    # Tên sản phẩm\n",
    "    dict_product_info['Name'] = soup.select('h1[class=\"Title__TitledStyled-sc-c64ni5-0 iXccQY\"]')[0].text\n",
    "\n",
    "    # Thương hiệu\n",
    "    dict_product_info['Brand'] = soup.select('a[data-view-id=\"pdp_details_view_brand\"]')[0].text\n",
    "\n",
    "    # Số lượng bán\n",
    "    sold_count = soup.select('div[data-view-id=\"pdp_quantity_sold\"]')\n",
    "    if sold_count != []:\n",
    "        dict_product_info['Quantity'] = soup.select('div[data-view-id=\"pdp_quantity_sold\"]')[0].text.split()[-1]\n",
    "    else:\n",
    "        dict_product_info['Quantity'] = 0\n",
    "\n",
    "    # Check lượt đánh giá\n",
    "    review_count = soup.select('a[data-view-id=\"pdp_main_view_review\"]')\n",
    "    if review_count != []:\n",
    "        # Số lượt đánh giá\n",
    "        dict_product_info['Reviews count'] = review_count[0].text.strip('()')\n",
    "\n",
    "        # Đánh giá sao\n",
    "        dict_product_info['Star rating'] = soup.select('div[class=\"styles__StyledReview-sc-1onuk2l-1 dRFsZg\"] > div')[0].text\n",
    "    else:\n",
    "        dict_product_info['Reviews count'] = 0\n",
    "\n",
    "    # Giá bán\n",
    "    dict_product_info['Price'] = soup.select('div[class=\"product-price__current-price\"]')[0].text.replace('₫', '')\n",
    "\n",
    "    # Ngày crawl\n",
    "    dict_product_info['Crawl date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Thông số lựa chọn (Màu sắc, dung lượng,...)\n",
    "    list_option_label = soup.select('div[class=\"styles__ProductOptionsWrapper-sc-18rzur4-0 jZCObm\"] > div')\n",
    "    if list_option_label != []:\n",
    "        for option_label in list_option_label:\n",
    "            list_option = option_label.select('div[class=\"styles__OptionListWrapper-sc-1pikfxx-2 jgDdBJ\"] > div')\n",
    "            list_all_option = []\n",
    "\n",
    "            for option in list_option:\n",
    "                list_all_option.append(option.text)\n",
    "\n",
    "            dict_product_info[option_label.attrs['data-view-label']] = ', '.join(list_all_option)\n",
    "\n",
    "    # Tên shop\n",
    "    dict_product_info['Shop name'] = soup.select('span[class=\"seller-name\"]')[1].text\n",
    "\n",
    "    # Đánh giá sao shop\n",
    "    dict_product_info['Shop rating'] = soup.select('div[class=\"item review\"] > div')[0].text\n",
    "\n",
    "    # Số lượt đánh giá shop\n",
    "    dict_product_info['Shop rating count'] = soup.select('div[class=\"item review\"] > div')[1].text.strip('()đánh giá')\n",
    "\n",
    "    # Thông tin chi tiết\n",
    "    product_info_soup = soup.select('div[class=\"WidgetTitle__WidgetContainerStyled-sc-12sadap-0 bufoOo\"]')[-5]\n",
    "    product_info = product_info_soup.select('div > div > div > span')\n",
    "\n",
    "    for i in range(0, len(product_info), 2):\n",
    "        # product_info[i].text: nhãn thông tin\n",
    "        # product_info[i+1].text: thông tin\n",
    "        dict_product_info[product_info[i].text] = product_info[i+1].text\n",
    "\n",
    "    # Mô tả sản phẩm\n",
    "    dict_product_info['Describe'] = soup.select('div[class=\"WidgetTitle__WidgetContainerStyled-sc-12sadap-0 bufoOo\"]')[-4].text\n",
    "\n",
    "    return dict_product_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(driver): # Hàm trả về 1 list reviews sản phẩm\n",
    "    all_reviews = []\n",
    "\n",
    "    while True:\n",
    "        # Bấm nút \"xem thêm\" để hiển thị tất cả nội dung review\n",
    "        show_more_btn_list = driver.find_elements(By.CSS_SELECTOR, 'span[class=\"show-more-content\"]')\n",
    "        if show_more_btn_list != []:\n",
    "            for show_more_btn in show_more_btn_list:\n",
    "                show_more_btn.click()\n",
    "\n",
    "        # Lấy soup mới\n",
    "        soup = get_soup(driver)\n",
    "\n",
    "        shop_name = soup.select('span[class=\"seller-name\"]')[1].text\n",
    "\n",
    "        # Lấy thông tin review\n",
    "        list_review = soup.select('div[class=\"style__StyledComment-sc-1y8vww-5 dpVjwc review-comment\"]')\n",
    "\n",
    "        for review in list_review:\n",
    "            dict_review = {}\n",
    "\n",
    "            # Tên shop\n",
    "            dict_review['Shop name'] = shop_name\n",
    "\n",
    "            # Tên\n",
    "            dict_review['Reviewer name'] = review.select('div[class=\"review-comment__user-name\"]')[0].text\n",
    "\n",
    "            # Nội dung\n",
    "            dict_review['Content'] = review.select('div[class=\"review-comment__content\"]')[0].text\n",
    "\n",
    "            # Đánh giá\n",
    "            dict_review['Rating'] = review.select('div[class=\"review-comment__title\"]')[0].text\n",
    "\n",
    "            # Thời gian đánh giá\n",
    "            dict_review['Rating date'] = review.select('div[class=\"review-comment__created-date\"] > span')[0].text\n",
    "\n",
    "            # Crawl date\n",
    "            dict_review['Crawl date'] = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "            all_reviews.append(dict_review)\n",
    "        \n",
    "        # Check có phải page cuối\n",
    "        try:\n",
    "            btn_color = driver.find_element(By.CSS_SELECTOR, 'a[class=\"btn next\"] > svg').get_attribute('color')\n",
    "            if btn_color == '#C4C4CF':\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        # Bấm chuyển page\n",
    "        driver.find_element(By.CSS_SELECTOR, 'a[class=\"btn next\"]').click()\n",
    "        sleep(5)\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lưu file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(list_of_dict, folder_path, file_name):\n",
    "    save_loc = r'%s%s.csv'%(folder_path, file_name)\n",
    "    exist_file = os.path.exists(save_loc)\n",
    "\n",
    "    if not exist_file:\n",
    "        df = pd.DataFrame(list_of_dict)\n",
    "        df.to_csv(save_loc, index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(save_loc)\n",
    "        df_new = pd.DataFrame(list_of_dict)\n",
    "        concat_file = pd.concat([df, df_new], ignore_index = True)\n",
    "\n",
    "        concat_file.to_csv(save_loc, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mở trình duyệt Google Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito') # Tab ẩn danh\n",
    "options.add_argument(\"--start-maximized\") # Full window\n",
    "options.add_argument('headless') # Không hiển thị chrome\n",
    "s = Service('../chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=s, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhập keyword (tên sản phẩm cần tìm kiếm)\n",
    "keyword = input('Keyword: ')\n",
    "\n",
    "# Tìm sản phẩm dựa vào keyword\n",
    "list_links = search_product(driver, keyword)\n",
    "\n",
    "# Lọc sản phẩm không liên quan và trích xuất url\n",
    "filter_url_list = filter_links(list_links, keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info = []\n",
    "product_reviews = []\n",
    "\n",
    "for product_url in filter_url_list:\n",
    "    product_soup = get_soup(driver, url=product_url)\n",
    "\n",
    "    product_info.append(get_product_info(product_soup))\n",
    "    \n",
    "    product_reviews = product_reviews + get_review(driver)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"..\\..\\Data\\Tiki\\\\\"\n",
    "\n",
    "# Lưu file product_info\n",
    "file_name_info = '%s_info'%('_'.join(keyword.split(' ')))\n",
    "save_csv(product_info, folder_path, file_name_info)\n",
    "\n",
    "# Lưu file reviews\n",
    "# file_name_reviews = '%s_reviews'%('_'.join(keyword.split(' ')))\n",
    "# save_csv(product_reviews, folder_path, file_name_reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
