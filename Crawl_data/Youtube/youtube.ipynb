{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thư viện cần tải\n",
    "# pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thư viện\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from string import punctuation\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk import ngrams\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Api key\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "api_key = 'AIzaSyAWkajTGnv9MuvV-xIOVX8M6SrIWnidgR8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lấy video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_id(url): # Trả về 1 chuỗi\n",
    "    y = requests.get(url)\n",
    "    soup = BeautifulSoup(y.content, 'lxml')\n",
    "    id = soup.select('meta[property=\"og:url\"]')[0].attrs['content'].split('/')[-1]\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_id_channel_file(list_links_channel):\n",
    "    # Check có tồn tại file channel_id.json\n",
    "    if not os.path.exists('channel_id.json'):\n",
    "        dict_id_channel = {} \n",
    "        \n",
    "        for channel in list_links_channel:\n",
    "            id = get_channel_id(channel)\n",
    "            dict_id_channel[channel] = id\n",
    "        \n",
    "        with open('channel_id.json', 'w') as file:\n",
    "            json.dump(dict_id_channel, file)\n",
    "    else:\n",
    "        # Check nếu thêm kênh mới\n",
    "        with open('channel_id.json', 'r') as f:\n",
    "            json_channel = json.load(f)\n",
    "\n",
    "            for link_channel in list_links_channel:\n",
    "                if link_channel not in json_channel:\n",
    "                    new_channel_id = get_channel_id(link_channel)\n",
    "                    json_channel[link_channel] = new_channel_id\n",
    "\n",
    "                    with open('channel_id.json', 'w') as add_new_id:\n",
    "                        json.dump(json_channel, add_new_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video(keyword, youtube): # Trả về 1 list\n",
    "    # List chứa video\n",
    "    list_video = []\n",
    "\n",
    "    # List chứa id kênh cần tìm\n",
    "    with open('channel_id.json', 'r') as f:\n",
    "        json_id = json.load(f)\n",
    "    list_id_channel = list(json_id.values())\n",
    "\n",
    "    for channel_id in list_id_channel:\n",
    "        search_request = youtube.search().list(part=\"snippet\",\n",
    "                                            maxResults=10, # YTB giới hạn tối 50 kết quả trả về\n",
    "                                            q=keyword, #  NOT (-) and OR (|)\n",
    "                                            channelId=channel_id,\n",
    "                                            type='video')\n",
    "\n",
    "        search_response = search_request.execute()\n",
    "\n",
    "        for vid in search_response['items']:\n",
    "            dict_vid = {}\n",
    "\n",
    "            # Video title\n",
    "            dict_vid['Video title'] = vid['snippet']['title']\n",
    "\n",
    "            # Video Id\n",
    "            dict_vid['Video Id'] = vid['id']['videoId']\n",
    "\n",
    "            list_video.append(dict_vid)\n",
    "\n",
    "    return list_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text): # Hàm tiền xử lí dữ liệu string và trả về 1 string\n",
    "    # Chữ hoa thành chữ thường\n",
    "    pre_text = text.lower()\n",
    "\n",
    "    # Loại bỏ dấu câu\n",
    "    for c in punctuation:\n",
    "        pre_text= pre_text.replace(c,' ')\n",
    "    \n",
    "    pre_text = \" \".join(pre_text.split())\n",
    "\n",
    "    return pre_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lọc video không liên quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_similar_keywords(text, keyword): # Hàm trích xuất từ khóa liên quan đến keyword trong text và trả về 1 list\n",
    "    smartphone_name = pd.read_csv('..\\smartphones.csv')['model']\n",
    "    similar_keywords_list = [name.lower() for name in smartphone_name if keyword in name.lower()]\n",
    "    extracted_keyword_list = []\n",
    "    main_topic_keyword_list = []\n",
    "\n",
    "    for similar_keyword in similar_keywords_list:\n",
    "        keyword_ngram_list = []\n",
    "        for n in range(2, len(similar_keyword)):\n",
    "            n_gram = ngrams(similar_keyword.split(), n)\n",
    "\n",
    "            for grams in n_gram:\n",
    "                keyword_ngram_list.append(list(grams))    \n",
    "\n",
    "        for keyword_ngram in keyword_ngram_list:\n",
    "            tokenizer = MWETokenizer()\n",
    "            tokenizer.add_mwe(keyword_ngram)\n",
    "            phrase_list = tokenizer.tokenize(text.split())\n",
    "\n",
    "            topic_keyword = '_'.join(keyword_ngram)\n",
    "            if topic_keyword in phrase_list:\n",
    "                extracted_keyword_list.append(keyword_ngram)\n",
    "\n",
    "    extracted_keyword_list.sort()\n",
    "    extracted_keyword_list = list(l for l,_ in itertools.groupby(extracted_keyword_list))\n",
    "\n",
    "    freq_extracted_keyword = {}\n",
    "\n",
    "    for l,_ in itertools.groupby(extracted_keyword_list):\n",
    "        kw = ' '.join(l)\n",
    "        freq_extracted_keyword[kw] = text.count(kw)\n",
    "\n",
    "    freq_extracted_keyword = sorted(list(freq_extracted_keyword.items()), key = lambda key : len(key[0]), reverse=True)\n",
    "    freq_extracted_keyword = {ele[0] : ele[1]  for ele in freq_extracted_keyword}\n",
    "\n",
    "    freq_key_list = list(freq_extracted_keyword.keys())\n",
    "    check_freq_dict = freq_extracted_keyword.copy()\n",
    "\n",
    "    for key in freq_key_list:\n",
    "        req = freq_extracted_keyword[key]\n",
    "\n",
    "        for check_key in freq_key_list:\n",
    "            if (key != check_key) and (key in check_key) and (check_freq_dict[check_key] > 0):\n",
    "                check_freq_dict[key] -= 1\n",
    "\n",
    "    for key, value in check_freq_dict.items():\n",
    "        if value > 0:\n",
    "            main_topic_keyword_list.append(key)\n",
    "    \n",
    "    return main_topic_keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_videos(list_video, keyword): # Hàm trích xuất Id của video nói về keyword và trả về 1 list\n",
    "    filter_video_id = []\n",
    "\n",
    "    for vid in list_video:\n",
    "        vid_title = vid['Video title']\n",
    "\n",
    "        pre_text = preprocessing(vid_title)\n",
    "\n",
    "        similar_keywords = extract_similar_keywords(pre_text, keyword)\n",
    "\n",
    "        if keyword in similar_keywords:\n",
    "            filter_video_id.append(vid['Video Id'])\n",
    "\n",
    "    return filter_video_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lấy thông tin và bình luận của video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(vid_id, youtube): # Trả về 1 list\n",
    "    comments_request = youtube.commentThreads().list(part=\"snippet, replies\", \n",
    "                                        videoId=vid_id, # Id của video cần crawl cmt\n",
    "                                        textFormat='plainText', # Cmt hiển thị ở dạng văn bản thường thay vì html\n",
    "                                        maxResults=100) # YTB chỉ cho phép lấy tối đa 100 cmt\n",
    "    comments_response = comments_request.execute()\n",
    "\n",
    "    list_comments = []\n",
    "\n",
    "    for item in comments_response['items']:\n",
    "        dict_comment = {}\n",
    "\n",
    "        # Video Id\n",
    "        dict_comment['Id'] = vid_id\n",
    "\n",
    "        # Bình luận\n",
    "        dict_comment['Comment'] = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\n",
    "        # Thời gian bình luận\n",
    "        dict_comment['Comment time'] = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "\n",
    "        # Phản hồi\n",
    "        if item['snippet']['totalReplyCount'] != 0:\n",
    "            list_replies = []\n",
    "\n",
    "            for replies in item['replies']['comments']:\n",
    "                reply = replies['snippet']['textDisplay']\n",
    "                list_replies.append(reply)\n",
    "\n",
    "            dict_comment['Reply'] = '<>'.join(list_replies) # Các phản hồi được ngăn cách bởi dấu <>\n",
    "        \n",
    "        list_comments.append(dict_comment)\n",
    "\n",
    "    # Chạy vòng lặp chuyển page lấy những cmt tiếp theo\n",
    "    while 'nextPageToken' in comments_response:\n",
    "        nextPageToken = comments_response['nextPageToken']\n",
    "        \n",
    "        next_comments_request = youtube.commentThreads().list(part=\"snippet, replies\", \n",
    "                                                    videoId=vid_id,\n",
    "                                                    textFormat='plainText',\n",
    "                                                    maxResults=100,\n",
    "                                                    pageToken=nextPageToken) \n",
    "        comments_response = next_comments_request.execute()\n",
    "\n",
    "        for item in comments_response['items']:\n",
    "            dict_comment = {}\n",
    "\n",
    "            # Video Id\n",
    "            dict_comment['Id'] = vid_id\n",
    "\n",
    "            # Bình luận\n",
    "            dict_comment['Comment'] = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "\n",
    "            # Thời gian bình luận\n",
    "            dict_comment['Comment time'] = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "\n",
    "            # Phản hồi\n",
    "            if item['snippet']['totalReplyCount'] != 0:\n",
    "                list_replies = []\n",
    "\n",
    "                for replies in item['replies']['comments']:\n",
    "                    reply = replies['snippet']['textDisplay']\n",
    "                    list_replies.append(reply)\n",
    "\n",
    "                dict_comment['Reply'] = '<>'.join(list_replies)\n",
    "                \n",
    "            list_comments.append(dict_comment)\n",
    "\n",
    "    return list_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(vid_id, youtube): # Trả về 1 dictionary\n",
    "    statistics_request = youtube.videos().list(part=\"snippet, statistics\",\n",
    "                                           id=vid_id)\n",
    "\n",
    "    statistics_response = statistics_request.execute()\n",
    "\n",
    "    dict_statistics = {}\n",
    "\n",
    "    # Video Id\n",
    "    dict_statistics['Id'] = vid_id\n",
    "\n",
    "    # Ngày đăng\n",
    "    published_at = statistics_response['items'][0]['snippet']['publishedAt']\n",
    "    dict_statistics['Date published'] = published_at\n",
    "\n",
    "    # Tiều đề\n",
    "    title = statistics_response['items'][0]['snippet']['title']\n",
    "    dict_statistics['Title'] = title\n",
    "\n",
    "    # Tiều đề kênh\n",
    "    channel_title = statistics_response['items'][0]['snippet']['channelTitle']\n",
    "    dict_statistics['Channel title'] = channel_title\n",
    "\n",
    "    # Lượt xem\n",
    "    view_count = statistics_response['items'][0]['statistics']['viewCount']\n",
    "    dict_statistics['View count'] = view_count\n",
    "\n",
    "    # Lượt like\n",
    "    like_count = statistics_response['items'][0]['statistics']['likeCount']\n",
    "    dict_statistics['Like count'] = like_count\n",
    "\n",
    "    # Lượt comments\n",
    "    comment_count = statistics_response['items'][0]['statistics']['commentCount']\n",
    "    dict_statistics['Comments count'] = comment_count\n",
    "\n",
    "    return dict_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube\n",
    "youtube = build(api_service_name, api_version, developerKey = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Những channel cần lấy reviews\n",
    "list_links_channel = ['https://www.youtube.com/@duythamchannel',\n",
    "                      'https://www.youtube.com/@realvatvostudio',\n",
    "                      'https://www.youtube.com/@duongde_official',\n",
    "                      'https://www.youtube.com/@tinhte',\n",
    "                      'https://www.youtube.com/@ReLab1008',\n",
    "                      'https://www.youtube.com/@vinhxo69',\n",
    "                      'https://www.youtube.com/@duyluandethuong',\n",
    "                      'https://www.youtube.com/@anhemtv',\n",
    "                      'https://www.youtube.com/@TonyPhungStudio',\n",
    "                      'https://www.youtube.com/@dienthoaivui',\n",
    "                      ] # Có thể thêm link vào\n",
    "\n",
    "# File channel_id.json chứa url channel và id của những kênh trong list_links_channel\n",
    "# Khởi tạo file channel_id.json nếu chưa có hoặc chỉnh sửa nếu có kênh mới trong list_links_channel\n",
    "check_id_channel_file(list_links_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhập keyword\n",
    "keyword = input('Keyword:').lower()\n",
    "\n",
    "# Tìm kiếm video trên Youtube dựa vào keyword\n",
    "list_video = get_video(keyword, youtube)\n",
    "\n",
    "# Lọc các video không liên quan đến keyword\n",
    "list_video_id = filter_videos(list_video, keyword)\n",
    "\n",
    "comments = []\n",
    "video_info = []\n",
    "for id in list_video_id:\n",
    "    cmt = get_comments(id, youtube)\n",
    "    comments += cmt\n",
    "\n",
    "    info = get_video_info(id, youtube)\n",
    "    video_info.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmts = pd.DataFrame(comments)\n",
    "df_cmts.to_csv(r'..\\..\\Data\\Youtube\\comments_' + '_'.join(keyword.split(' ')) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_video_info = pd.DataFrame(video_info)\n",
    "df_video_info.to_csv(r'..\\..\\Data\\Youtube\\video_info_' + '_'.join(keyword.split(' ')) + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
