{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df_social = pd.read_csv('../Data/Preprocessed_data/SocialMediaReviews.csv')\n",
    "df_social.drop(columns=['ViewCount'],inplace=True)\n",
    "df_social.dropna(inplace=True)\n",
    "print(len(df_social))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df_social['Review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "from nltk import word_tokenize\n",
    "\n",
    "documents = df_social['Review']\n",
    "stopwords = set(open('./vietnamese-stopwords.txt', encoding='utf-8').read().split('\\n')[:-1])\n",
    "puct_set = set([c for c in '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^`{|}~'])\n",
    "\n",
    "def generateBigram(review):\n",
    "    words = review.split()\n",
    "    if len(words)==1:\n",
    "        return ''\n",
    "    bigrams = [words[i]+'_'+words[i+1] for i in range(0,len(words)-1)]\n",
    "    return ' '.join(bigrams)\n",
    "\n",
    "def removeRedundant(text,redundantSet):\n",
    "    words = text.split()\n",
    "    for i in range(0,len(words)):\n",
    "        if words[i].count('_') == 0 and (words[i] in redundantSet or words[i].isdigit()):\n",
    "            words[i] = ''\n",
    "        else:\n",
    "            sub_words = words[i].split('_')\n",
    "            if any(w in redundantSet or w.isdigit() for w in sub_words):\n",
    "                words[i] = ''\n",
    "    words = [w for w in words if w != '']\n",
    "    words = ' '.join(words)\n",
    "    return words\n",
    "\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = ' '.join(word_tokenize(text))\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    text = text + generateBigram(text)\n",
    "    text = removeRedundant(text,puct_set | stopwords)\n",
    "    return text\n",
    "\n",
    "clean_documents =  documents.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vi·∫øt c·∫ßm pro max v·ªõi m√¨nh ch·∫≥ng t√≠ch_c·ª±c ƒë√†n y·∫øu_ƒëu·ªëi th·∫ø b√†i_vi·∫øt vs_m m_ch·∫≥ng t√≠ch_c·ª±c _ƒë√†n y·∫øu_ƒëu·ªëi'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_preprocessed.preprocessing_text('vi·∫øt c·∫ßm 14prm vs m ch·∫≥ng üòÜ ƒë√†n y·∫øu ƒëu·ªëi th·∫ø b√†i_vi·∫øt vs_m m_ch·∫≥ng üòÜ_ƒë√†n y·∫øu_ƒëu·ªëi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "from text_preprocessed import preprocessing_text\n",
    "\n",
    "try:\n",
    "    cleaned_documents = documents.apply(preprocessing_text)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156                                ƒë∆∞·ª£c c√°i m√£ b√™n ngo√†i\n",
       "157                                    c√°i m√£ ngo√†i   ƒë√≥\n",
       "158                             v·∫´n ch∆∞a hi·ªÉu t√≠ch_c·ª±c  \n",
       "159    b√™n ng√†nh √¥ng t√¥ ng∆∞·ªùi_ta g·ªçi facelift n√¢ng_c·∫•...\n",
       "160    m·∫•y th·∫±ng member tinhte t·ª´_t·ª•c th·∫•y chia_s·∫ª th...\n",
       "161    gi√†u b·∫±ng m·ªì_h√¥i c·ªßa m√¨nh th√¨ khoe m·∫°nh l√™n ae...\n",
       "162    m√¨nh kh√¥ng ganh_gh√©t hay ƒë·ªë_k·ªã nh·ªØng ng∆∞·ªùi gi√†...\n",
       "163    ch·ªâ ch·ª≠i nh∆∞ng l·∫°i kh√¥ng ganh_gh√©t ƒë·ªë_k·ªµ   hay...\n",
       "164         ch·∫•p l√†m g√¨   n√≥ ch·∫Øc ƒëang iphone n√™n cay_c√∫\n",
       "165    gi√†u ch√¢n_ch√≠nh m√† khoe th√¨ ƒë√°ng ng∆∞·ªüng m·ªô ch·ª©...\n",
       "166    nhi·ªÅu ng∆∞·ªùi mua iphone l√†m ƒë·ªông m·ªì ƒë·ªông m·∫£ b·ªçn...\n",
       "167                             gato k√¨a l√™u l√™u   cay √†\n",
       "168                             b·ªõt s√¢n si v√† ƒë·ªë_k·ªµ ƒëi  \n",
       "169    ranh_con   c√≥ t√≠ ti·ªÅn ƒë√£ khoe_khoang   mu·ªën l√†...\n",
       "170    Ranh con, c√≥ t√≠ ti·ªÅn ƒë√£ khoe khoang, mu·ªën l√†m ...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[155:170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from text_preprocessed import convert_emoji,remove_abbreviations,remove_replicated\n",
    "# from pyvi import ViTokenizer\n",
    "# text = \"C√≥ m·ªói iphone  m√† c·∫£ tu·∫ßn n√†y tinh t·∫ø x√†o n·∫•u kho h√¢m l·∫°i ch·∫Øc d√πng 2 th√°ng m·ªõi h·∫øt ü§£\"\n",
    "# text_pre = text.lower()\n",
    "# import re\n",
    "# # Lo·∫°i b·ªè url\n",
    "# text_pre = re.sub(r'http\\S+', '', text_pre)\n",
    "\n",
    "# # Lo·∫°i b·ªè t√™n mi·ªÅn\n",
    "# text_pre = re.sub(r\"[^\\s]*\\.(com|vn|net)\", '', text_pre)\n",
    "\n",
    "# # Lo·∫°i b·ªè hashtag\n",
    "# text_pre = ' '.join(re.sub(\"(#[A-Za-z0-9]+)\", \" \", text_pre).split())\n",
    "\n",
    "# # Lo·∫°i b·ªè user mentions @\n",
    "# text_pre = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \" \", text_pre).split())\n",
    "\n",
    "# # Lo·∫°i b·ªè d·∫•u xu·ªëng d√≤ng \\r, \\n v√† tab \\t\n",
    "# text_pre = text_pre.replace('\\r', ' ').replace('\\n', ' ').replace('\\t', ' ')\n",
    "\n",
    "# # Bi·∫øn ƒë·ªïi emoji\n",
    "# # text_pre = convert_emoji(text_pre)\n",
    "\n",
    "# # Lo·∫°i b·ªè ch·ªØ b·ªã l·∫∑p\n",
    "# text_pre = remove_replicated(text_pre)\n",
    "\n",
    "# # Lo·∫°i b·ªè ch·ªØ s·ªë\n",
    "# text_pre = re.sub(\"\\d+\", \" \", text_pre)\n",
    "\n",
    "# # Lo·∫°i b·ªè t·ª´ vi·∫øt t·∫Øt v√† vi·∫øt sai\n",
    "# text_pre = remove_abbreviations(text_pre)\n",
    "\n",
    "# # Tokenize\n",
    "# text_pre = ViTokenizer.tokenize(text_pre)\n",
    "\n",
    "# # Lo·∫°i b·ªè d·∫•u c√¢u v√† k√≠ t·ª±\n",
    "# text_pre = re.sub(r'[^\\s\\w√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√≠√¨·ªâƒ©·ªã√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë√Å√Ä·∫¢√É·∫†ƒÇ·∫Æ·∫∞·∫≤·∫¥·∫∂√Ç·∫§·∫¶·∫®·∫™·∫¨√â√à·∫∫·∫º·∫∏√ä·∫æ·ªÄ·ªÇ·ªÑ·ªÜ√ì√í·ªé√ï·ªå√î·ªê·ªí·ªî·ªñ·ªò∆†·ªö·ªú·ªû·ª†·ª¢√ç√å·ªàƒ®·ªä√ö√ô·ª¶≈®·ª§∆Ø·ª®·ª™·ª¨·ªÆ·ª∞√ù·ª≤·ª∂·ª∏·ª¥ƒê_]', ' ', text_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c√≥ m·ªói iphone m√† c·∫£ tu·∫ßn n√†y tinh_t·∫ø x√†o_n·∫•u kho h√¢m l·∫°i ch·∫Øc d√πng th√°ng m·ªõi h·∫øt  '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtext_preprocessed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing_text\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpreprocessing_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC√≥ m·ªói iphone  m√† c·∫£ tu·∫ßn n√†y tinh t·∫ø x√†o n·∫•u kho h√¢m l·∫°i ch·∫Øc d√πng 2 th√°ng m·ªõi h·∫øt ü§£\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\OneDrive - mrsnguyen\\DUE\\KLTN\\KhoaLuanGr3-Code\\Model\\text_preprocessed.py:172\u001b[0m, in \u001b[0;36mpreprocessing_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    169\u001b[0m text_pre \u001b[38;5;241m=\u001b[39m text_pre\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Bi·∫øn ƒë·ªïi emoji\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m text_pre \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_emoji\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_pre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Lo·∫°i b·ªè ch·ªØ b·ªã l·∫∑p\u001b[39;00m\n\u001b[0;32m    175\u001b[0m text_pre \u001b[38;5;241m=\u001b[39m remove_replicated(text_pre)\n",
      "File \u001b[1;32md:\\OneDrive - mrsnguyen\\DUE\\KLTN\\KhoaLuanGr3-Code\\Model\\text_preprocessed.py:138\u001b[0m, in \u001b[0;36mconvert_emoji\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m EMOJI_DATA:\n\u001b[0;32m    137\u001b[0m     sen_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 138\u001b[0m     sen_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt√≠ch c·ª±c\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mget_emoji_sentiment_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpositive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    139\u001b[0m     sen_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb√¨nh th∆∞·ªùng\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_emoji_sentiment_rank(t)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    140\u001b[0m     sen_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mti√™u c·ª±c\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_emoji_sentiment_rank(t)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from text_preprocessed import preprocessing_text\n",
    "print(preprocessing_text(\"C√≥ m·ªói iphone  m√† c·∫£ tu·∫ßn n√†y tinh t·∫ø x√†o n·∫•u kho h√¢m l·∫°i ch·∫Øc d√πng 2 th√°ng m·ªõi h·∫øt ü§£\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row at index 771: 'NoneType' object is not subscriptable\n",
      "C√≥ m·ªói iphone  m√† c·∫£ tu·∫ßn n√†y tinh t·∫ø x√†o n·∫•u kho h√¢m l·∫°i ch·∫Øc d√πng 2 th√°ng m·ªõi h·∫øt ü§£\n",
      "Error processing row at index 817: 'NoneType' object is not subscriptable\n",
      "B√†i n√†y t·ª´ h·ªìi \n",
      "iphone 11\n",
      "iphone 12\n",
      "iphone 13\n",
      "iphone 14\n",
      "iphone 15\n",
      "‚Ä¶\n",
      "\n",
      "‚ÄúH·ªïng ƒëc, h√¨nh em g√°i n√†y ch∆∞a xinh, c≈© r√πi‚Ä¶‚Äù\n",
      "\n",
      "√Åi ch√†, copy paste m·ªèi nay r√πi s·ª≠a th√™m c·∫©n th·∫≠n k·∫ªo anh em l·∫°i m·∫Øng oan taü§£\n",
      "Error processing row at index 868: 'NoneType' object is not subscriptable\n",
      "Su·ªµt n√≥i nh·ªè th√¥i, n√≥ l·∫°i b·∫£o t√°i ƒë·ªãnh nghƒ©a ch·ª© ko b·∫£o ƒëi sao ch√©p ƒë√¢u ü§£ü§£ü§£\n",
      "Error processing row at index 888: 'NoneType' object is not subscriptable\n",
      "mu·ªën h·∫øt n√≥ng th√¨ ƒë·ª£i apple ra b·∫£n update gi·∫£m hi·ªáu nƒÉng A17 Pro th√¥i ü§£\n",
      "Error processing row at index 900: 'NoneType' object is not subscriptable\n",
      "ƒê·ªãnh nghƒ©a ü§£ü§£ü§£ VƒÉn c·ªßa m·∫•y th·∫±ng ifan kh√° h√†i h∆∞·ªõc\n",
      "Error processing row at index 1187: 'NoneType' object is not subscriptable\n",
      "S·ªëng ·ªü VN m√† ko hi·ªÉu ti·∫øng vi·ªát ahü§ê. L·∫°i v·∫∑n ‚Äúkh√¥ng kh√°c‚Äù v√† ‚Äúko kh√°c nhi·ªÅu‚Äù th√¨ t√¥i c≈©ng  ·∫° b·∫°n.\n",
      "Error processing row at index 1201: 'NoneType' object is not subscriptable\n",
      "Th·∫ø c∆° √†...üòÇü§£ü§£üòÇü§£\n",
      "Error processing row at index 1255: 'NoneType' object is not subscriptable\n",
      "Th√¨ ·ªü tinhte Apple l√† t√¥n gi√°o m√† b·∫°n, c√°i Apple pay c√≥ g√¨ ƒë√¢u m√† c≈©ng b√∫ 20-30 b√†i, iPhone th√¨ ch·∫Øc ph·∫£i x2 ü§°\n",
      "Error processing row at index 1306: 'NoneType' object is not subscriptable\n",
      "Dm b·∫±ng tay c∆° ak ü§£\n",
      "Error processing row at index 1323: 'NoneType' object is not subscriptable\n",
      "C√°c ch√°u b·∫£o ƒë·ªôt ph√° l·∫Øm b√°cü§£ü§£ü§£ü§£\n",
      "Error processing row at index 1416: 'NoneType' object is not subscriptable\n",
      "N·∫∑ng l·∫Øm ü§£ü§£üòÇ\n",
      "Error processing row at index 1426: 'NoneType' object is not subscriptable\n",
      "M·ªÅm nh∆∞ iphone 6plus ü§£\n",
      "Error processing row at index 1576: 'NoneType' object is not subscriptable\n",
      "Crop tr√™n c·∫£m bi·∫øn v·∫´n t√≠nh l√† zoom quang sao ü§£\n",
      "Error processing row at index 1668: 'NoneType' object is not subscriptable\n",
      "Ch·ª•p ss up b·∫±ng IP, m√¨nh ƒëang √°p d·ª•ng ü§£\n",
      "Error processing row at index 1669: 'NoneType' object is not subscriptable\n",
      "·ª¶a, c√°i n√†y c√≥ th·∫≠t ah? M√¨nh t∆∞·ªüng ch·ªâ l√† tin ƒë·ªìn th√¥i ch·ª©? üôÇ\n",
      "Error processing row at index 1714: 'NoneType' object is not subscriptable\n",
      "Tui ƒëang x√†i ip m√† nghe b·∫°n n√≥i c∆∞·ªùi ƒëau b·ª•ng ..x√†i con s23 ultra ch∆∞a hay n√≥i ƒë·∫°i v·∫≠y ü§£\n",
      "Error processing row at index 1738: 'NoneType' object is not subscriptable\n",
      "ƒêi kh√°m m·∫Øt v·ªõi ƒëo ƒëi·ªán n√£o l·∫°i ƒëi c∆∞ng. C√≥ khi nh√¨n √°m v√†ng ri·∫øt nh√¨n b√¨nh th∆∞·ªùng l·∫°i ra √°m xanh, k·∫ªo t·ªëi nh√¨n v·ª£ t∆∞·ªüng b·ªã blue clam n·ªØa ü§£\n",
      "Error processing row at index 1780: 'NoneType' object is not subscriptable\n",
      "ƒê·ªÉ m·∫•y con bot ƒëi dizz th·∫•y comment n√†o smart th√¨ t·ª± ngu th√¥i, sai p√† n√≥ ch·ª©c nƒÉng r·ªìi ü§£\n",
      "Error processing row at index 1922: 'NoneType' object is not subscriptable\n",
      "ƒê·ªÉ nguy√™n b·∫£n m√† b√°n ko ƒë·ªÉ. S∆°n xanh l√™n xong ·∫ø m√†u xanh b·∫°n nh·ªâ  ü§£\n",
      "Error processing row at index 1924: 'NoneType' object is not subscriptable\n",
      "Haha t∆∞·ªüng t·ª± nhi√™n th√¨ h·∫Øn ph·∫£i t·ª± nhi√™n ü§£\n",
      "Error processing row at index 1961: 'NoneType' object is not subscriptable\n",
      "Kh√≥ c√≥ ƒë·ªëi th·ªß m√† ch·∫≥ng d√°m so s√°nh v·ªõi ƒë·ªëi th·ªß n√†o ü§£\n",
      "Error processing row at index 2137: 'NoneType' object is not subscriptable\n",
      "Sao th·∫•y n√≥ ch∆∞a b·∫±ng 5x tr√™n note 20 ultra ta üôÑüôÑ\n",
      "Error processing row at index 2240: 'NoneType' object is not subscriptable\n",
      "Vi·∫øt b√†i b·ªã l·ªói ch√≠nh t·∫£ hay b·ªã nh·∫ßm l√† ƒë·∫∑c s·∫£n c·ªßa Tinh t·∫ø r·ªìi. C≈©ng do l√¢y t·ª´ tay ch·ªß t·ªãch Ku Hi·ªáp m√† ra. \n",
      "N√™n m·∫•y b√°c c·ª© th√¥ng c·∫£m nh√©. ü§£\n",
      "Error processing row at index 2318: 'NoneType' object is not subscriptable\n",
      "V·∫≠y ai b·∫£o l√† iPhone kh√¥ng c·∫ßn nhi·ªÅu b·ªô nh·ªõ Ram ü§£ü§£ü§£ü§£ü§£ b√¢y gi·ªù r√µ r·ªìi nh√© ! iPhone n√≥ c≈©ng nh∆∞ androi th√¥i . Kh√¥ng tr√°nh ƒë∆∞·ª£c ki·∫øp nh√¢n sinh ƒë√¢u\n",
      "Error processing row at index 2323: 'NoneType' object is not subscriptable\n",
      "ƒêg suy nghƒ© ch·ªçn m√†u. C≈©ng k quan t√¢m l·∫Øm m·∫•y c√°i th√¥ng s·ªë n√†y ü§£ü§£ü§£. H√¨nh nh∆∞ t·ª´ l√¢u r·ªìi.\n",
      "Error processing row at index 2324: 'NoneType' object is not subscriptable\n",
      "Ram 6GB tr√™n iphone l√† th·∫•y d∆∞ d√πng r·ªìi ü§£ü§£\n",
      "Error processing row at index 2331: 'NoneType' object is not subscriptable\n",
      "8GB RAM Apple = 32GB RAM Android ü§£\n",
      "Error processing row at index 2371: 'NoneType' object is not subscriptable\n",
      "Lo·∫°i gian x·∫£o l·∫°i c√≤n Ch√≠ Ph√®o, ai d·∫°y cu th·∫ø ƒë·∫•y ü§£\n",
      "Error processing row at index 2446: 'NoneType' object is not subscriptable\n",
      "Th·∫ø ra m√†y vi·∫øt c·∫£ ch·ª•c c√°i cmt ch·ªâ ƒë·ªÉ l·∫∑p ƒëi l·∫∑p l·∫°i c√°i ai-c≈©ng-bi·∫øt ƒë·∫•y √†, ƒë√∫ng l√† th·∫±ng kh√πng, ai ch·∫£ bi·∫øt sau post n√†y th√¨ khai trung th·ª±c ƒë√≥ l√† c√°ch ph√≤ng m·∫•t tg ngo√†i √Ω mu·ªën, sau post n√†y ngta t·ª± r√µ, c·∫ßn m√†y l·∫∑p c·∫£ ch·ª•c c√°i cmt ƒë·ªÉ n√≥i qu√°, ch·∫øt c∆∞·ªùi. Quan tr·ªçng r·ªìi trung th·ª±c xong v·∫´n c√≥ kh·∫£ nƒÉng m·∫•t ti·ªÅn, ƒë√≥ m·ªõi l√† c√°i ngta b√†n lu·∫≠n, m·∫π ƒë√∫ng th·∫±ng kh√πng, h√≥a ra n√≥ n√≥i kh√¥ng ƒë√¢u ü§£\n",
      "Error processing row at index 2479: 'NoneType' object is not subscriptable\n",
      "Ngh√¨n t·ª∑ m√† l√†m ƒÉn ch√°n ƒë·ªùi ü§£...n√≥ ƒë·∫∑t c√°i store online xong m√† ko ch∆°i full ti·∫øng Vi·ªát l√† ƒë·ªß hi·ªÉu n√≥ xem th∆∞·ªùng c·ª° n√†oüôÑ\n",
      "Error processing row at index 2535: 'NoneType' object is not subscriptable\n",
      "C·ªông nhi·ªÅu qu√° b·∫°n kia t√≠nh kh√¥ng k·ªãpü§£\n",
      "Error processing row at index 2619: 'NoneType' object is not subscriptable\n",
      "Gi·ªëng m√¨nh, l√†m vi·ªác v·ªõi ti·∫øng anh h√†ng ng√†y nh∆∞ng nh·ªØng d√≤ng nh∆∞ n√†y ƒë√∫ng ... Nu·ªët kh√¥ng tr√¥i, ch·∫Øc n√≥ th√†nh trap ü§£ü§£ü§£\n",
      "Error processing row at index 2702: 'NoneType' object is not subscriptable\n",
      "V√¨ c·∫ßm iporn v·∫´n s∆∞·ªõng chim h∆°n c·∫ßm h√† thi√™n l·ªôn √° bro ∆°i ü§£\n",
      "Error processing row at index 2837: 'NoneType' object is not subscriptable\n",
      "Nghƒ© theo h∆∞·ªõng t√≠ch c·ª±c ƒëi b√¢c. Ph·∫£i c√≥ nhi·ªÅu con g√† ƒë·ªÉ l√πa nh∆∞ b√°c th√¨ apple m·ªõi c√≥ th·ªÉ tr·ªü th√†nh t·∫≠p ƒëo√†n ngh√¨n t·ª∑ ƒë√¥ la. ƒê·ªÉ t·ª´ ƒë√≥ c√≥ th·ªÉ cho ra nh·ªØng con ip m·ªõi ƒë·ªÉ b√°c d√πng ch·ª© ü§£ü§£ü§£\n",
      "Error processing row at index 2857: 'NoneType' object is not subscriptable\n",
      "Ch∆°i kh·ªën n·∫°n th·∫≠t, ƒë·ªõp c·∫£ c·ªßa ng∆∞·ªùi d√πng c√° nh√¢n lu√¥n. Ch√∫c m·ª´ng m√†y ƒë∆∞·ª£c tao ch·∫•p nh·∫≠n thu mua m√°y v·ªõi gi√° 0ƒëü§£ü§£ü§£. Kh√©o nh√¢n vi√™n n√≥ ƒëem v·ªÅ cho ng∆∞·ªùi nh√† s√†i lu√¥n r·ªìi\n",
      "Error processing row at index 2931: 'NoneType' object is not subscriptable\n",
      "Kh√≥ ph√¢n bi·ªát th·∫≠t üôÑ\n",
      "Error processing row at index 2964: 'NoneType' object is not subscriptable\n",
      "B·∫°n ∆°i? B·∫°n ƒë·ªçc kh√¥ng hi·ªÉu r√µ n·ªôi dung r·ªìi ·∫•n x√°c nh·∫≠n r·ªìi k√™u ng∆∞·ªùi ta l·ª´a b·∫°n l√† sao? Ki·ªÉu v·ª´a ƒÉn c∆∞·ªõp v·ª´a la l√†ng √Ω. T·∫°i sao m√¨nh ko m·∫°nh d·∫°ng nh·∫≠n m√¨nh sai? M√¨nh d·ªët ngo·∫°i ng·ªØ v√† chia s·∫ª l·∫°i c√°i s·ª± sai l·∫ßm c·ªßa m√¨nh??? T·∫°i sao l·∫°i b·∫£o h·ªç b·∫´y? Qu√° tr√¨nh h·ªç th·∫©m ƒë·ªãnh m√°y c·ªßa b·∫°n l√† v·ªõi nh√† m√°y ? M√† nh√† m√°y n√≥ ko c√≥ nghƒ©a v·ª• ph·∫£i reply b·∫±ng ti·ªÅn Vi·ªát ƒë√¢u ·∫°? V√† h·ªç g·ª≠i n·ªôi dung r√µ r√†ng do m√¨nh d·ªãch qua loa th√¨ ch·∫•p nh·∫≠n v·ªõi c√°i SAI c·ªßa m√¨nh ƒëi ƒë√£ b·∫£o h·ªç TRAP m√¨nh üôèüèª\n",
      "Error processing row at index 2966: 'NoneType' object is not subscriptable\n",
      "Ch∆∞a k·ªÉ l√∫c khai b√°o t√¨nh tr·∫°ng sao kh√¥ng k√™ khai m√°y m√¨nh b·ªã b·ªÉ k√≠nh l∆∞ng? Mu·ªën l·ª´a n√≥ tr∆∞·ªõc ƒë·ªÉ thu ƒë∆∞·ª£c g√≠a cao ai ng·ªù b·ªã m·∫Øc x∆∞∆°ng ng∆∞·ª£c l·∫°i l√™n g√†o th√©t nh∆∞ ki·ªÉu b·ªã h·∫°i, v·ªõi t√¨nh tr·∫°ng m√°y nh∆∞ th·∫ø ra h√†ng n√≥ c≈©ng ch·∫£ thu dc t·ªõi 7tr üôèüèª m√† ƒë√≤i l·ª´a T∆∞ B·∫£n tr∆∞·ªõc ü§£\n",
      "Error processing row at index 2971: 'NoneType' object is not subscriptable\n",
      "Uhm th√¨ m√¨nh d·ªët ti·∫øng Vi·ªát nh∆∞ng m√¨nh kh√¥ng b·∫°o bi·ªán cho s·ª± ngu d·ªët ƒë√≥. C√≤n ph·∫£n bi·ªán cho c·ªë xong ‚Äúb·ªã l·ª´a‚Äù 1 c√°ch ƒë√°ng s·ª£ l√† th√¥ng ƒëi·ªáp c·∫ßn ƒë∆∞·ª£c truy·ªÅn t·∫£i r·ªông r√£i l√™n n√®. B·∫°n auto ƒë√∫ng, v√† b·∫°n l√† nh·∫•t ü•á okay ‚òùüèª\n",
      "Error processing row at index 2980: 'NoneType' object is not subscriptable\n",
      "B√°c c√£i ko l·∫°i t·ª•i ch√≥ h√πa ƒë√¢u, ng∆∞·ªùi vi·∫øt Sai r·ªìi kh√¥ng n√≥i, nh∆∞ng th√†nh ph·∫ßn h√πa theo ƒë·ªÉ b·∫£o bi·ªán cho c√°i Sai ƒë√≥ th√†nh b√¨nh th∆∞·ªùng m·ªõi l√† th√†nh ph·∫ßn nguy hi·ªÉm. Thay v√†o  ·ªü ƒë√≥ c·∫ßu th·ªã h·ªçc h·ªèi, th·ª´a nh·∫≠n m√¨nh SAI v√† D·ªêT tr∆∞·ªõc ƒëi ƒë√£ th√¨ ·ªü ƒë√¢y n√≥ c√≤n l·∫≠p lu·∫≠n ngo·∫∑c k√©p v·ªõi ngo·∫∑c vu√¥ng ? \n",
      "\n",
      "‚Äú b·ªã l·ª´a ‚Äú 1 c√°ch ƒë√°ng s·ª£ m√† n√≥ ph·∫£n bi·ªán l√† m√¨nh d·ªët ti·∫øng vi·ªát n√™n kh√¥ng hi·ªÉu √Ω th√†nh t√¢m h·ªëi c·∫£i nh·∫≠n sai nh·∫≠n d·ªët c·ªßa ch·ªß b√†i vi·∫øt th√¨ c≈©ng qu·ª≥ üôèüèª 1 c√¢u n√≥i kinh ƒëi·ªÉn : kh√¥ng th·ªÉ ch·ªëng l·∫°i l≈© Ngu v√¨ ch√∫ng qu√° ƒë√¥ng ü§£\n",
      "Error processing row at index 2988: 'NoneType' object is not subscriptable\n",
      "V·∫≠y b·ªõt l∆∞∆°n l·∫πo ƒëi ƒë·ªÉ ng∆∞·ªùi ta kh·ªèi coi th∆∞·ªùng üôÉ\n",
      "Error processing row at index 2992: 'NoneType' object is not subscriptable\n",
      "L√†m ƒÉn ·ªü Vi·ªát Nam nh∆∞ng ƒëo·∫°n tr·ªçng t√¢m ta ch∆°i ti·∫øng anh, b·∫°n nghƒ© n√≥ ƒë·ªÉ cho m√¨nh c√≥ c∆° h·ªôi report kh√¥ng ü§£ü§£ü§£\n",
      "Error processing row at index 2995: 'NoneType' object is not subscriptable\n",
      "M·ªôt th·∫±ng l∆∞∆°n l·∫πo ngay t·ª´ ƒë·∫ßu r·ªìi ƒë·ªï th·ª´a ng∆∞·ªùi ta l·ª´a ƒë·∫£o üôÉ ch√°n nh·∫•t l√† ƒë·ª©a v√†o cmt b√™nh n·ªØa. Ph·∫£i ngay t·ª´ ƒë·∫ßu m√¨nh ngay th·∫≥ng th√¨ m·ªõi ƒë·ªß t∆∞ c√°ch n√≥i ng∆∞·ªùi kh√°c l·ª´a ƒë·∫£o ch·ª© ü§£\n",
      "Error processing row at index 3118: 'NoneType' object is not subscriptable\n",
      "Ra c·ª≠a h√†ng trade in c√°i l√† c√≥ m√°y m·ªõi v·ªõi gi√° r·∫ª h∆°n tr√™n apple store üôÇ\n",
      "Error processing row at index 3202: 'NoneType' object is not subscriptable\n",
      "Ncl r√°ch. Kh√≥c t·ª´ b√™n group ip sang ƒë√¢y c≈©ng ƒë ai b√™nh. T√≠nh l·ª´a tk apple nh∆∞ng ko ƒëc quay ra cay c√∫ √† üôÇ\n",
      "Error processing row at index 3220: 'NoneType' object is not subscriptable\n",
      "Kh√≥c than ng∆∞·ªùi kh√°c l·ª´a m√¨nh trong khi ch√≠nh b·∫£n th√¢n ƒë√£ ch·ªß ƒë·ªông l·ª´a ng∆∞·ªùi kh√°c, c√≤n tr·∫ª th√¨ h·ªçc th√≥i trung th·ª±c ngay t·ª´ ƒë·∫ßu thay v√¨ d√πng nh·ªØng ng√¥n t·ª´ tho√° m·∫° ng∆∞·ªùi kh√°c. R√°ch üôÉ \n",
      "Ô£¨ Sent from CRAZYSEXYCOOL1981 using BlackBerry Athena Ô£¨\n",
      "Error processing row at index 3243: 'NoneType' object is not subscriptable\n",
      "Trong khi iPhone n√†o c≈©ng b·ªÅn vl ra m√† m·∫•y th·∫±ng ng√°o ch∆∞a ƒë∆∞·ª£c s·ªù con 15 pro bao h ph√°n nh∆∞ d√∫ng r·ªìi ü§£\n",
      "Error processing row at index 3313: 'NoneType' object is not subscriptable\n",
      "C√¢u h·ªèi ch√≠ m·∫°ng ü§£\n",
      "Error processing row at index 3383: 'NoneType' object is not subscriptable\n",
      "H·ªìi gi·ªù A v·∫´n l√†m khung nh√¥m v·ªõi khung inox m√† b·∫°n ü§£\n",
      "Error processing row at index 3413: 'NoneType' object is not subscriptable\n",
      "Nguy√™n t·∫Øc l√†m ki·∫øm nh·∫°t th·∫ø n√†o n√≥i nghe ch∆°i b·∫°n, coi th·ª≠ c√≥ gi·ªëng v·ªõi c√°ch apple l√†m ko ü§£\n",
      "Error processing row at index 3429: 'NoneType' object is not subscriptable\n",
      "üå∂Ô∏èüå∂Ô∏èüå∂Ô∏è üòÜ\n",
      "Error processing row at index 3440: 'NoneType' object is not subscriptable\n",
      "‚ÄúAnh em n√≥i khung s∆∞·ªùn iPhone 15 Pro b·∫±ng Titanium l√† kh√¥ng ƒë√∫ng. N√≥ l√† b·∫±ng nh√¥m v√† ph·ªß Titanium.‚Äù\n",
      "\n",
      "√îng lo m√† k√™u ƒë√°m mod nh√¢n vi√™n s·ª≠a l·∫°i m·∫•y b√†i vi·∫øt t·ª´ h√¥m qua t·ªõi gi·ªù ƒëi k√¨a! ƒê·∫ßy th√≠m h√¥ l√† khung titanium ü§£ ü§£ ü§£\n",
      "Error processing row at index 3465: 'NoneType' object is not subscriptable\n",
      "B·∫±ng titan v·ªõi ph·ªß titan l√† hai kh√°i ni·ªám kh√°c nhau. T√≥m l·∫°i c√°i khung v·∫´n l√† nh√¥m. B·∫°n ko th·ªÉ l·∫•y c√°i nh·∫´n b·∫°c m·∫° v√†ng l√™n xong g·ªçi n√≥ l√† nh·∫´n v√†ng ƒëc ü§î\n",
      "Error processing row at index 3470: 'NoneType' object is not subscriptable\n",
      "ƒê·∫≥ng c·∫•p cao n√™n gi√° c≈©ng ph·∫£i t∆∞∆°ng x·ª©ng ü§ë\n",
      "Error processing row at index 3491: 'NoneType' object is not subscriptable\n",
      "N√≥i chung l√† c≈©ng √©o c√≥ g√¨ th√∫ v·ªã , ƒë√†ng b·ªìi n√†o 98% ng∆∞·ªùi d√πng ch·∫£ ·ªëp , d√°n ... c√°c ki·ªÉu . T c√≤n th·∫•y c√≥ th·ªÉ lo·∫°i b√¨nh th∆∞·ªùng th√¨ ƒëeo ·ªëp k√≠n m√≠t , xong khi n√†o ng·ªìi ƒë√¢u sang ch·∫£nh , ha oai th√¨ th√°o ·ªëp ƒë·ªÉ tr·∫ßn xong n√¢ng nh∆∞ n√¢ng bi v·∫≠y ü§£ü§£ü§£\n",
      "Error processing row at index 3500: 'NoneType' object is not subscriptable\n",
      "C√°i m√†u gold sang ch·∫£nh ƒë·ªùi 15 l·∫°i k c√≥, ch√°n ch·∫£ mu·ªën l√™n ƒë·ªùi ae ·∫°, t√¥i v·∫´n s√†i ti·∫øp 14pro max ü§£ 15 ko c√≥ g√¨ h·∫•p d·∫´n l·∫Øm ae ·∫°\n",
      "Error processing row at index 3535: 'NoneType' object is not subscriptable\n",
      "hai c√°i ƒë√≥ l√† hai ph·∫ßn ri√™ng bi·ªát, theo nh∆∞ c√°ch h·ªç n√≥i hai c√°i ƒë√≥ ph·∫ßn ti·∫øp x√∫c tr·ªôn l·∫´n l·∫°i dz·ªõi nhau, m√† ƒë·ªÉ hai c√°i ƒë√≥ tr·ªôn l·∫´n ƒë∆∞·ª£c th√¨ ch·ªâ c√≥ nung ch·∫£y ch·ªó ti·∫øp x√∫c ƒë√≥, m√† ƒë·ªÉ ch·ªâ nung ch·∫£y ph·∫ßn ph·∫ßn ti·∫øp x√∫c ƒë√≥ cho t·ª•i n√≥ tr·ªôn dz√¥ nhau m√† h√¥ng ·∫£nh h∆∞·ªüng t·ªõi c√°i vi·ªÅn c√°i khung thi c√¥ng ngh·ªá gh√™ thi·ªác, hay ch·ªâ l√† c√°ch n√≥i qu√° ch·ªõ th·∫∑c s·ª± ch·ªâ xi m·∫° ü§£ü§£ü§£\n",
      "Error processing row at index 3678: 'NoneType' object is not subscriptable\n",
      "V·∫´n ko h∆°n g√¨ con iPhone 16 Pro Max ƒëang x√†i, b·ªè qua ƒë∆∞·ª£c r·ªìi üôÇ\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m         documents\u001b[38;5;241m.\u001b[39mloc[index] \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing row at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\OneDrive - mrsnguyen\\DUE\\KLTN\\KhoaLuanGr3-Code\\Model\\text_preprocessed.py:181\u001b[0m, in \u001b[0;36mpreprocessing_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    178\u001b[0m text_pre \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, text_pre)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Lo·∫°i b·ªè t·ª´ vi·∫øt t·∫Øt v√† vi·∫øt sai\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m text_pre \u001b[38;5;241m=\u001b[39m \u001b[43mremove_abbreviations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_pre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Tokenize\u001b[39;00m\n\u001b[0;32m    184\u001b[0m text_pre \u001b[38;5;241m=\u001b[39m ViTokenizer\u001b[38;5;241m.\u001b[39mtokenize(text_pre)\n",
      "File \u001b[1;32md:\\OneDrive - mrsnguyen\\DUE\\KLTN\\KhoaLuanGr3-Code\\Model\\text_preprocessed.py:100\u001b[0m, in \u001b[0;36mremove_abbreviations\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_abbreviations\u001b[39m(text):\n\u001b[1;32m--> 100\u001b[0m     abbreviations \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabbreviations.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     remove_abbreviations_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io \u001b[38;5;241m=\u001b[39m stringify_path(path_or_buffer)\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;66;03m# Determine xlrd version if installed\u001b[39;00m\n\u001b[1;32m-> 1550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxlrd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1551\u001b[0m     xlrd_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\compat\\_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    127\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing optional dependency \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse pip or conda to install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m )\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1544\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error_indices = []\n",
    "\n",
    "for index, row in enumerate(documents):\n",
    "    try:\n",
    "        documents.loc[index] = preprocessing_text(row)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row at index {index}: {e}\")\n",
    "        print(row)\n",
    "        error_indices.append(index)\n",
    "\n",
    "print(\"Rows with errors:\", error_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100      d√†i qu√° ƒë·ªçc ƒë∆∞·ª£c b√†i r·ªìi em cu√¥n xu·ªëng v√† ƒëi ra\n",
       "101    k·ªÉ h·∫øt c√°c ƒëi·ªÉm tr√™n con iphone ƒë·ªùi_m·ªõi t√≠ch_c...\n",
       "102    b√†i n√†y vi·∫øt ch·ªß_ƒë·ªÅ l√Ω_do mua t·ª´ th√°ng tr∆∞·ªõc r...\n",
       "103    v·∫≠y_m√† iphone pro max b√¨nh_ch·ªçn t·ªët nh·∫•t ch·∫Øc ...\n",
       "104                                            th·ª´a ti·ªÅn\n",
       "                             ...                        \n",
       "496                   ƒë·ªÉ mua iphone pro max th·ª≠ t√≠ch_c·ª±c\n",
       "497                            th·ªõt ch·ª•p m·∫•y t·∫•m ƒë·∫πp qu√°\n",
       "498                                               c·∫£m_∆°n\n",
       "499    c√°i x l√† c√°i v√¥_d·ª•ng nh·∫•t   ·∫£nh ch·ª•p x ra nh√¨n...\n",
       "500    n·∫øu ch·ª•p trong ƒëi·ªÅu_ki·ªán thi·∫øu s√°ng m√† n√©t cƒÉn...\n",
       "Name: Review, Length: 400, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_documents = [doc for doc in clean_documents if doc != '']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction = LSA = TruncatedSVD(TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruncatedSVD,PCA\n\u001b[0;32m      4\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(token_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS+\u001b[39m\u001b[38;5;124m\"\u001b[39m, min_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m vectors \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mclean_documents\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTf-idf shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(vectors\u001b[38;5;241m.\u001b[39mshape))\n\u001b[0;32m      9\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_documents' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern = \"\\S+\", min_df = 2)\n",
    "vectors = vectorizer.fit_transform(clean_documents)\n",
    "\n",
    "print(\"Tf-idf shape: \" + str(vectors.shape))\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=10, random_state=42)\n",
    "svd_vectors = svd.fit_transform(vectors)\n",
    "\n",
    "print(\"Document 1's Vector : \")\n",
    "print(svd_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruncatedSVD,PCA\n\u001b[0;32m      3\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m  TfidfVectorizer(token_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS+\u001b[39m\u001b[38;5;124m\"\u001b[39m,min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_documents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2138\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2133\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2134\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2135\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2136\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2137\u001b[0m )\n\u001b[1;32m-> 2138\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2140\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1386\u001b[0m             )\n\u001b[0;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1295\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1293\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1296\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1297\u001b[0m         )\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD,PCA\n",
    "vectorizer =  TfidfVectorizer(token_pattern=\"S+\",min_df=2)\n",
    "vectors = vectorizer.fit_transform(cleaned_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "\n",
    "def vietnamese_tokenizer(text):\n",
    "    return ViTokenizer.tokenize(text)\n",
    "\n",
    "# Initialize TfidfVectorizer with Vietnamese tokenizer\n",
    "vectorizer = TfidfVectorizer(tokenizer=vietnamese_tokenizer)\n",
    "\n",
    "# Fit and transform the documents\n",
    "vectors = vectorizer.fit_transform(cleaned_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf shape:(60285, 394)\n",
      "Document 1's Vector : \n",
      "[ 9.75689395e-01 -3.66864101e-02  3.76155339e-02 -6.66627690e-03\n",
      "  2.35498501e-02  3.35414139e-02  2.97596616e-02 -1.32784354e-02\n",
      "  4.37651133e-02 -1.09132991e-01 -5.40689923e-03 -1.40232757e-02\n",
      " -7.15484564e-03  7.47907831e-03  2.95028372e-02  1.59393085e-02\n",
      "  5.28207376e-02  1.50690770e-02  1.06979634e-02 -9.89425938e-03\n",
      "  2.57207745e-04  4.06022106e-03  1.33053934e-02 -6.88813313e-03\n",
      " -1.35034359e-02  1.09001277e-02  4.11336451e-03  1.08588695e-02\n",
      "  1.35921669e-02 -3.09220443e-02 -2.88219392e-02  3.38235836e-02\n",
      "  1.74701702e-02  5.71909025e-03 -2.50218230e-02  2.21057832e-02\n",
      " -2.92006185e-02 -1.56376770e-02 -2.66019461e-03 -9.59141384e-03\n",
      "  1.81684431e-02 -2.18200257e-02 -1.42638019e-02  1.27177427e-02\n",
      "  3.50329398e-02  9.08934671e-03  1.48472162e-05 -7.05407752e-04\n",
      " -2.94085798e-02  2.51918361e-03 -1.08195184e-02  1.04738744e-02\n",
      "  2.40394748e-02 -1.33588051e-03 -4.97608382e-04  7.02950472e-03\n",
      "  1.22409105e-03  7.58772890e-04 -1.12639586e-02 -1.47705711e-02\n",
      " -7.76125199e-03 -2.45931162e-02  2.49884396e-02  9.89173337e-03\n",
      "  1.09829001e-02 -1.01014453e-02 -3.02612986e-02  1.57956155e-03\n",
      "  3.41346197e-02  5.90523462e-03  2.64357334e-03 -4.08774168e-03\n",
      "  1.16695492e-02  8.11889902e-03 -1.37122628e-02  6.19757359e-03\n",
      " -6.44510616e-03 -2.56077505e-02  4.10276600e-02  8.76990136e-03\n",
      " -1.16751439e-02  1.19514915e-02 -3.71195585e-03 -1.89898878e-02\n",
      " -4.35153324e-03  4.56490207e-02  3.78031669e-03  1.12083299e-02\n",
      "  4.18567147e-03  1.52733407e-02  8.29465132e-03  2.67628350e-02\n",
      "  8.54974967e-03  5.97867377e-03 -3.95386179e-03  1.27299956e-02\n",
      " -3.17871673e-03 -2.78422294e-03  3.47048495e-03  1.98022806e-02]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tfidf shape:\"+str(vectors.shape))\n",
    "svd = TruncatedSVD(n_components=100,n_iter=10)\n",
    "svd_vectors=svd.fit_transform(vectors)\n",
    "print(\"Document 1's Vector : \")\n",
    "print(svd_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 460. MiB for an array with shape (1000, 60285) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\nguye\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\nguye\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\nguye\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\nguye\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nguye\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_17832\\3119295640.py\", line 31, in distance\n  File \"c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 2331, in pairwise_distances\n    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n  File \"c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1871, in _parallel_pairwise\n    return func(X, Y, **kwds)\n  File \"c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 186, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1108, in cosine_distances\n    S = cosine_similarity(X, Y)\n  File \"c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 186, in wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\", line 1665, in cosine_similarity\n    K = safe_sparse_dot(X_normalized, Y_normalized.T, dense_output=dense_output)\n  File \"c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\extmath.py\", line 208, in safe_sparse_dot\n    ret = a @ b\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 460. MiB for an array with shape (1000, 60285) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [39], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m vector_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks_vec(svd_vectors, \u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Use joblib for parallel processing\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m Dis_matrices \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvector_chunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Process results incrementally\u001b[39;00m\n\u001b[0;32m     45\u001b[0m Dis_matrix \u001b[38;5;241m=\u001b[39m Dis_matrices[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 460. MiB for an array with shape (1000, 60285) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "def distance(vecs):\n",
    "    vec1 = vecs[0]\n",
    "    vecAll = vecs[1]\n",
    "    Dis_matrix = pairwise_distances(vec1,vecAll,metric = 'cosine',n_jobs=1)\n",
    "    Dis_matrix = Dis_matrix.astype(np.float16)\n",
    "    return Dis_matrix\n",
    "\n",
    "def chunks_vec(l, n):\n",
    "    for i in range(0, l.shape[0], n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "vector_chunks = list(chunks_vec(svd_vectors,1000))\n",
    "vector_chunks = [(i,svd_vectors) for i in vector_chunks]\n",
    "\n",
    "pool = Pool(2)\n",
    "Dis_matrix = pool.map(distance,vector_chunks)\n",
    "Dis_matrix = np.vstack(Dis_matrix)\n",
    "pool.terminate()\n",
    "\n",
    "print('cosine distance between Document 1 and Document 2 : ', Dis_matrix[0][2])\n",
    "print('cosine distance between Document 2 and Document 3 : ', Dis_matrix[2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "graph = deepcopy(Dis_matrix)\n",
    "graph[graph <= THRESHOLD] = 2\n",
    "graph[graph != 2] = 0\n",
    "graph[graph == 2] = 1\n",
    "graph = graph.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import connected_components\n",
    "res = connected_components(graph,directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "cluster_labels = res[1]\n",
    "num_cluster = res[0]\n",
    "res_cluster = OrderedDict()\n",
    "\n",
    "for i in range(0,len(cluster_labels)):\n",
    "    if cluster_labels[i] in res_cluster: res_cluster[cluster_labels[i]].append(i)\n",
    "    else: res_cluster[cluster_labels[i]] = [i]\n",
    "\n",
    "res_cluster = [res_cluster[i] for i in range(0,num_cluster)]\n",
    "res_cluster = [sorted(r) for r in res_cluster if len(r) > 1]\n",
    "res_cluster.sort(key=len,reverse=True)\n",
    "\n",
    "print(\"Number of cluster: \", len(res_cluster))\n",
    "print(\"Number of clustered documents: \", len([j for i in res_cluster for j in i]))\n",
    "print(\"Number of noise documents: \", len(documents) - len([j for i in res_cluster for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(res_cluster)):\n",
    "    print(\"Cluster \" + str(i))\n",
    "    for idx in res_cluster[i]:\n",
    "        print(documents[idx].split('\\n')[0])\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
