{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import dateutil.relativedelta\n",
    "from re import sub\n",
    "import os.path\n",
    "# import pypyodbc as odbc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.copy_on_write = True\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive_name = 'SQL SERVER'\n",
    "# server_name = 'DESKTOP-29355SM\\SQLEXPRESS'\n",
    "# database_name = 'Bank'\n",
    "\n",
    "# connection_string = f\"\"\"\n",
    "#     DRIVER={{{drive_name}}};\n",
    "#     SERVER={server_name};\n",
    "#     DATABASE={database_name};\n",
    "#     Trust_Connection=yes;\n",
    "# \"\"\"\n",
    "\n",
    "# conn = odbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute(\"\"\"\n",
    "# Create table Persons (\n",
    "#     PersonID int,\n",
    "#     LastName varchar(255),\n",
    "#     FirstName varchar(255),\n",
    "#     Address varchar(255),\n",
    "#     City varchar(255)\n",
    "# )\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql('Select * from account', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_review(text_date, crawl_date): # Biến đổi khoảng thời gian (1 tháng trước, 2 ngày trước) thằnh ngày cụ thể và trả về datetime\n",
    "    sub_text = text_date.split(' ')\n",
    "    date_cmt = ''\n",
    "\n",
    "    if 'năm' in text_date:\n",
    "        for t in sub_text:\n",
    "            if t.isnumeric():\n",
    "                date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(years=int(t))\n",
    "    elif 'tháng' in text_date:\n",
    "        for t in sub_text:\n",
    "            if t.isnumeric():\n",
    "                date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(months=int(t))\n",
    "    elif 'tuần' in text_date:\n",
    "        for t in sub_text:\n",
    "            if t.isnumeric():\n",
    "                date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(weeks=int(t))\n",
    "    elif 'ngày' in text_date:\n",
    "        for t in sub_text:\n",
    "            if t.isnumeric():\n",
    "                date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(days=int(t))\n",
    "    else:\n",
    "        date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date()\n",
    "\n",
    "    return str(date_cmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id(last_id): # Tạo ID mới và trả về string\n",
    "    last_id_list = []\n",
    "    newest_id = ''\n",
    "\n",
    "    for s in list(last_id):\n",
    "        if s.isnumeric():\n",
    "            last_id_list.append(s)\n",
    "        else:\n",
    "            newest_id += s\n",
    "    \n",
    "    last_id = str(int(''.join(last_id_list)) + 1)\n",
    "    if len(last_id_list) != len(last_id):\n",
    "        num_0 = len(last_id_list) - len(last_id)\n",
    "        newest_id += '0'*num_0 + last_id\n",
    "    else:\n",
    "        newest_id += last_id\n",
    "    \n",
    "    return newest_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data(file_table_name, df, id_format=None): # Thêm df vào file save\n",
    "    # Lưu ý: df không chứa cột ID, thứ tự cột và định dạng giống với file save và nếu file save trống thì cần đưa ID format (S000, PL00,...)\n",
    "    table = pd.read_csv(r'..\\Data\\Preprocessed_data\\%s'%(file_table_name))\n",
    "\n",
    "    # Loại bỏ những dòng trong df đã có trong table\n",
    "    drop_index = []\n",
    "    for index in range(len(df)):\n",
    "        if list(df.iloc[index]) in table[table.columns[1:]].values.tolist():\n",
    "            drop_index.append(index)\n",
    "    df.drop(drop_index, inplace=True)\n",
    "\n",
    "    newest_id = ''\n",
    "    if id_format != None:\n",
    "        newest_id = create_id(id_format)\n",
    "    else:\n",
    "        newest_id = create_id(table.iloc[-1][0])\n",
    "\n",
    "    list_id = []\n",
    "    for i in range(len(df)):\n",
    "        list_id.append(newest_id)\n",
    "        newest_id = create_id(newest_id)\n",
    "    df.insert(loc=0, column='ID', value=list_id)\n",
    "\n",
    "    df.columns = table.columns\n",
    "    table = pd.concat([table, df], ignore_index=True)\n",
    "    table.to_csv(r'..\\Data\\Preprocessed_data\\%s'%(file_table_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shop(new_shop_df): # Thêm shop mới vào file Shop.csv (new_shop_df chỉ bao gồm 'Shop name', 'Shop rating' và đặt đúng thứ tự)\n",
    "    shop_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Shop.csv')\n",
    "    check_shop_list = new_shop_df.drop_duplicates(subset=new_shop_df.columns[0], keep='last', ignore_index=True)\n",
    "    drop_index = []\n",
    "\n",
    "    for index_shop in range(len(check_shop_list)):\n",
    "        if check_shop_list.iloc[index_shop][0] in shop_df['ShopName'].values:\n",
    "            drop_index.append(index_shop)\n",
    "\n",
    "    check_shop_list.drop(drop_index, inplace=True)\n",
    "\n",
    "    if len(shop_df) == 0:\n",
    "        add_data('Shop.csv', check_shop_list, id_format='S000')\n",
    "    else:\n",
    "        add_data('Shop.csv', check_shop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Platform.csv')\n",
    "product_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Product.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in product_df.to_dict(orient='records'):\n",
    "    product_name = p['ProductName'].lower()\n",
    "    # Kiểm tra file data có tồn tại hay không\n",
    "    file_path = r'..\\Data\\Tiki\\%s_info.csv'%('_'.join(product_name.split(' ')))\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        tiki_product_info = pd.read_csv(file_path)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Loại bỏ dấu \".\" trong cột \"Price\" và đổi định dạng thành int\n",
    "    tiki_product_info['Price'] = tiki_product_info['Price'].str.replace('.', '').astype(int)\n",
    "\n",
    "    # Tạo và giữ nguyên thông tin bán ở những ngày crawl mới đối với shop không còn bán sp\n",
    "    for name in tiki_product_info['Name'].unique():\n",
    "        all_day_crawl = list(tiki_product_info['Crawl date'].unique())\n",
    "        crawl_date = tiki_product_info[tiki_product_info['Name'] == name]['Crawl date'].values\n",
    "        check_day = []\n",
    "\n",
    "        for day in all_day_crawl:\n",
    "            if day in crawl_date:\n",
    "                check_day.append(all_day_crawl.index(day))\n",
    "\n",
    "        if len(check_day) == 1 and check_day[0] != len(tiki_product_info['Crawl date'].unique())-1:\n",
    "            value = tiki_product_info[(tiki_product_info['Name'] == name) & (tiki_product_info['Crawl date'] == all_day_crawl[check_day[0]])]\n",
    "            list_df_copy = []\n",
    "            for index in range(len(tiki_product_info['Crawl date'].unique()[check_day[0]+1:])):\n",
    "                list_df_copy.append(value.copy())\n",
    "\n",
    "            for i in range(len(list_df_copy)):\n",
    "                list_df_copy[i].loc[value.index[0], 'Crawl date'] = all_day_crawl[check_day[0]+1:][i]\n",
    "\n",
    "            new_date_values = pd.concat(list_df_copy, ignore_index=True)\n",
    "            tiki_product_info = pd.concat([tiki_product_info, new_date_values], ignore_index=True)\n",
    "        elif len(check_day) > 1 and len(check_day) != len(all_day_crawl):\n",
    "            check_list = []\n",
    "\n",
    "            for i in range(len(check_day) - 1):\n",
    "                dict_check = {}\n",
    "                if check_day[i+1] - check_day[i] != 1:\n",
    "                    dict_check[check_day[i]] = [x for x in range(check_day[i]+1, check_day[i+1])]\n",
    "                    check_list.append(dict_check)\n",
    "\n",
    "            if check_day[-1] != len(all_day_crawl)-1:\n",
    "                check_list.append({check_day[-1]: [x for x in range(check_day[-1]+1, len(all_day_crawl))]})\n",
    "\n",
    "            new_date_values = pd.DataFrame(columns=tiki_product_info.columns)\n",
    "            for dict in check_list:\n",
    "                for k, v in dict.items():\n",
    "                    value = tiki_product_info[(tiki_product_info['Name'] == name) & (tiki_product_info['Crawl date'] == all_day_crawl[k])]\n",
    "                    list_df_copy = []\n",
    "                    for index in range(len(v)):\n",
    "                        list_df_copy.append(value.copy())\n",
    "                    \n",
    "                    for i in range(len(list_df_copy)):\n",
    "                        list_df_copy[i].loc[value.index[0], 'Crawl date'] = all_day_crawl[v[i]]\n",
    "                    \n",
    "                    new_date_values = pd.concat([new_date_values] + list_df_copy, ignore_index=True)\n",
    "\n",
    "            tiki_product_info = pd.concat([tiki_product_info, new_date_values], ignore_index=True)\n",
    "\n",
    "    # Thêm cột ID của sp\n",
    "    tiki_product_info['ProductID'] = p['ProductID']\n",
    "\n",
    "    # Thêm cột ID của platform\n",
    "    tiki_product_info['PlatformID'] = 'PL01'\n",
    "\n",
    "    # Thêm shop mới vào file Shop.csv nếu có\n",
    "    shop_list = tiki_product_info[['Shop name', 'Shop rating']].copy()\n",
    "    add_shop(shop_list)\n",
    "\n",
    "    # Thêm ID của shop\n",
    "    shop_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Shop.csv')\n",
    "    for shop_name in shop_df['ShopName']:\n",
    "        tiki_product_info.loc[tiki_product_info['Shop name'] == shop_name, 'ShopID'] = shop_df[shop_df['ShopName']==shop_name]['ShopID'].values[0]\n",
    "\n",
    "    # Kiểm tra thiếu cột giá trị\n",
    "    add_list = ['ProductID', 'PlatformID', 'ShopID', 'Price', 'Quantity', 'Reviews count', 'Star rating', 'Storage', 'Crawl date']\n",
    "    \n",
    "    for col in add_list:\n",
    "        if col not in tiki_product_info.columns:\n",
    "            tiki_product_info[col] = np.NaN\n",
    "\n",
    "    add_df = tiki_product_info[add_list].copy()\n",
    "\n",
    "    # Lưu vào file save Market.csv\n",
    "    market_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Market.csv')\n",
    "    if len(market_df) == 0:\n",
    "        add_data('Market.csv', add_df, 'MK000')\n",
    "    else:\n",
    "        add_data('Market.csv', add_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in product_df.to_dict(orient='records'):\n",
    "    product_name = p['ProductName'].lower()\n",
    "    # Kiểm tra file data có tồn tại hay không\n",
    "    file_path = r'..\\Data\\Tiki\\%s_reviews.csv'%('_'.join(product_name.split(' ')))\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        tiki_reviews = pd.read_csv(file_path)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Biến đổi cột 'Rating date' thành ngày cụ thể thông qua 'Crawl date'\n",
    "    actual_date_list = []\n",
    "\n",
    "    for num in range(len(tiki_reviews)):\n",
    "        text_date = tiki_reviews.loc[num, ['Rating date', 'Crawl date']][0]\n",
    "        crawl_date = tiki_reviews.loc[num, ['Rating date', 'Crawl date']][1]\n",
    "\n",
    "        actual_date = extract_date_review(text_date, crawl_date)\n",
    "        actual_date_list.append(actual_date)\n",
    "\n",
    "    tiki_reviews['Rating date'] = actual_date_list\n",
    "\n",
    "    # Biến đổi cột \"Rating\" thành thang đo likert\n",
    "    rating_likert = {'Rất không hài lòng': 1, 'Không hài lòng': 2, 'Bình thường': 3, 'Hài lòng': 4, 'Cực kì hài lòng': 5}\n",
    "\n",
    "    for num in range(len(tiki_reviews)):\n",
    "        rating = tiki_reviews.loc[num, 'Rating']\n",
    "        for k, v in rating_likert.items():\n",
    "            if rating == k:\n",
    "                tiki_reviews.loc[num, 'Rating'] = v\n",
    "\n",
    "    # Loại bỏ những dòng trùng \"Reviewer name\" và \"Content\"\n",
    "    tiki_reviews.drop_duplicates(subset=['Reviewer name', 'Content'], keep='last', inplace=True, ignore_index=True)\n",
    "\n",
    "    # Thêm cột ID của sp\n",
    "    tiki_reviews['ProductID'] = p['ProductID']\n",
    "\n",
    "    # Thêm cột ID của platform\n",
    "    tiki_reviews['PlatformID'] = 'PL01'\n",
    "\n",
    "    # Thêm ID của shop\n",
    "    shop_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Shop.csv')\n",
    "    for shop_name in shop_df['ShopName']:\n",
    "        tiki_reviews.loc[tiki_reviews['Shop name'] == shop_name, 'ShopID'] = shop_df[shop_df['ShopName']==shop_name]['ShopID'].values[0]\n",
    "\n",
    "    add_df = tiki_reviews[['Content', 'ProductID', 'PlatformID', 'Rating date', 'ShopID', 'Rating']].copy()\n",
    "\n",
    "    # Lưu vào file save Market.csv\n",
    "    ecom_reviews_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\EcomReviews.csv')\n",
    "    if len(ecom_reviews_df) == 0:\n",
    "        add_data('EcomReviews.csv', add_df, 'ER00000000')\n",
    "    else:\n",
    "        add_data('EcomReviews.csv', add_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in product_df.to_dict(orient='records'):\n",
    "    product_name = p['ProductName'].lower()\n",
    "    # Kiểm tra file data có tồn tại hay không\n",
    "    file_path = r'..\\Data\\Lazada\\%s_info.csv'%('_'.join(product_name.split(' ')))\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        lazada_product_info = pd.read_csv(file_path)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Chỉnh sửa cột \"Quantity\" thành số\n",
    "    if 'int' not in str(lazada_product_info['Quantity'].dtypes):\n",
    "        for index in range(len(lazada_product_info)):\n",
    "            count = lazada_product_info.loc[index, 'Quantity']\n",
    "            sold_count = ''\n",
    "            x = 0\n",
    "\n",
    "            if not count.isnumeric():\n",
    "                if 'k' in count or 'K' in count:\n",
    "                    x = 1000\n",
    "                sold_count = count.replace('.', '')\n",
    "                sold_count = sub('\\D', '', count)\n",
    "                if len(sold_count) == 1:\n",
    "                    sold_count = int(sold_count) * x\n",
    "                elif len(sold_count) == 2:\n",
    "                    sold_count = int(sold_count) * int(x/10)\n",
    "            else:\n",
    "                sold_count = int(count)\n",
    "\n",
    "            lazada_product_info.loc[index, 'Quantity'] = sold_count\n",
    "            \n",
    "        for sku in lazada_product_info['SKU'].unique():\n",
    "            previous_quantity = 0\n",
    "\n",
    "            for index in lazada_product_info[lazada_product_info['SKU'] == sku].index:\n",
    "                quantity = lazada_product_info[lazada_product_info['SKU'] == sku].loc[index, 'Quantity']\n",
    "\n",
    "                if quantity < previous_quantity:\n",
    "                    lazada_product_info.loc[index, 'Quantity'] = previous_quantity\n",
    "                else:\n",
    "                    previous_quantity = quantity\n",
    "    \n",
    "    # Tạo và giữ nguyên thông tin bán ở những ngày crawl mới đối với shop không còn bán sp\n",
    "    for sku in lazada_product_info['SKU'].unique():\n",
    "        all_day_crawl = list(lazada_product_info['Crawl date'].unique())\n",
    "        crawl_date = lazada_product_info[lazada_product_info['SKU'] == sku]['Crawl date'].values\n",
    "        check_day = []\n",
    "\n",
    "        for day in all_day_crawl:\n",
    "            if day in crawl_date:\n",
    "                check_day.append(all_day_crawl.index(day))\n",
    "\n",
    "        if len(check_day) == 1 and check_day[0] != len(lazada_product_info['Crawl date'].unique())-1:\n",
    "            value = lazada_product_info[(lazada_product_info['SKU'] == sku) & (lazada_product_info['Crawl date'] == all_day_crawl[check_day[0]])]\n",
    "            list_df_copy = []\n",
    "            for index in range(len(lazada_product_info['Crawl date'].unique()[check_day[0]+1:])):\n",
    "                list_df_copy.append(value.copy())\n",
    "\n",
    "            for i in range(len(list_df_copy)):\n",
    "                list_df_copy[i].loc[value.index[0], 'Crawl date'] = all_day_crawl[check_day[0]+1:][i]\n",
    "\n",
    "            new_date_values = pd.concat(list_df_copy, ignore_index=True)\n",
    "            lazada_product_info = pd.concat([lazada_product_info, new_date_values], ignore_index=True)\n",
    "        elif len(check_day) > 1 and len(check_day) != len(all_day_crawl):\n",
    "            check_list = []\n",
    "\n",
    "            for i in range(len(check_day) - 1):\n",
    "                dict_check = {}\n",
    "                if check_day[i+1] - check_day[i] != 1:\n",
    "                    dict_check[check_day[i]] = [x for x in range(check_day[i]+1, check_day[i+1])]\n",
    "                    check_list.append(dict_check)\n",
    "\n",
    "            if check_day[-1] != len(all_day_crawl)-1:\n",
    "                check_list.append({check_day[-1]: [x for x in range(check_day[-1]+1, len(all_day_crawl))]})\n",
    "\n",
    "            new_date_values = pd.DataFrame(columns=lazada_product_info.columns)\n",
    "            for dict in check_list:\n",
    "                for k, v in dict.items():\n",
    "                    value = lazada_product_info[(lazada_product_info['SKU'] == sku) & (lazada_product_info['Crawl date'] == all_day_crawl[k])]\n",
    "                    list_df_copy = []\n",
    "                    for index in range(len(v)):\n",
    "                        list_df_copy.append(value.copy())\n",
    "                    \n",
    "                    for i in range(len(list_df_copy)):\n",
    "                        list_df_copy[i].loc[value.index[0], 'Crawl date'] = all_day_crawl[v[i]]\n",
    "                    \n",
    "                    new_date_values = pd.concat([new_date_values] + list_df_copy, ignore_index=True)\n",
    "\n",
    "            lazada_product_info = pd.concat([lazada_product_info, new_date_values], ignore_index=True)\n",
    "\n",
    "    # Chỉnh sửa cột \"Reviews count\" thành số\n",
    "    for index in range(len(lazada_product_info)):\n",
    "        review_count = lazada_product_info.loc[index, 'Reviews count']\n",
    "        if review_count == 'Không có đánh giá':\n",
    "            lazada_product_info.loc[index, 'Reviews count'] = 0\n",
    "        else:\n",
    "            lazada_product_info.loc[index, 'Reviews count'] = int(review_count.replace('đánh giá', ''))\n",
    "\n",
    "    # Chỉnh sửa cột \"Shop rating\" về thang đo 5\n",
    "    for index in range(len(lazada_product_info)):\n",
    "        shop_rating = lazada_product_info.loc[index, 'Shop rating']\n",
    "\n",
    "        if shop_rating == 'Không có đánh giá':\n",
    "            lazada_product_info.loc[index, 'Shop rating'] = ''\n",
    "        else:\n",
    "            rating = int(sub('\\D', '', shop_rating))\n",
    "            lazada_product_info.loc[index, 'Shop rating'] = round((5*rating)/100, 1)\n",
    "\n",
    "    # Thêm cột ID của sp\n",
    "    lazada_product_info['ProductID'] = p['ProductID']\n",
    "\n",
    "    # Thêm cột ID của platform\n",
    "    lazada_product_info['PlatformID'] = 'PL02'\n",
    "\n",
    "    # Thêm shop mới vào file Shop.csv nếu có\n",
    "    shop_list = lazada_product_info[['Shop name', 'Shop rating']].copy()\n",
    "    add_shop(shop_list)\n",
    "\n",
    "    # Thêm ID của shop\n",
    "    shop_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Shop.csv')\n",
    "    for shop_name in shop_df['ShopName']:\n",
    "        lazada_product_info.loc[lazada_product_info['Shop name'] == shop_name, 'ShopID'] = shop_df[shop_df['ShopName']==shop_name]['ShopID'].values[0]\n",
    "\n",
    "    # Kiểm tra thiếu cột giá trị\n",
    "    add_list = ['ProductID', 'PlatformID', 'ShopID', 'Price', 'Quantity', 'Reviews count', 'Star rating', 'Storage', 'Crawl date']\n",
    "    for col in add_list:\n",
    "        if col not in lazada_product_info.columns:\n",
    "            lazada_product_info[col] = np.NaN\n",
    "\n",
    "    add_df = lazada_product_info[add_list].copy()\n",
    "\n",
    "    # Lưu vào file save Market.csv\n",
    "    market_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Market.csv')\n",
    "    if len(market_df) == 0:\n",
    "        add_data('Market.csv', add_df, 'MK000')\n",
    "    else:\n",
    "        add_data('Market.csv', add_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in product_df.to_dict(orient='records'):\n",
    "    product_name = p['ProductName'].lower()\n",
    "\n",
    "    lazada_reviews = pd.read_csv(r'..\\Data\\Lazada\\%s_reviews.csv'%('_'.join(product_name.split(' '))))\n",
    "\n",
    "    # Biến đổi cột 'Rating date' thành ngày cụ thể thông qua 'Crawl date'\n",
    "    actual_date_list = []\n",
    "\n",
    "    for num in range(len(lazada_reviews)):\n",
    "        text_date = lazada_reviews.loc[num, ['Rating date', 'Crawl date']][0]\n",
    "        if 'trước' in text_date:\n",
    "            crawl_date = lazada_reviews.loc[num, ['Rating date', 'Crawl date']][1]\n",
    "            actual_date = extract_date_review(text_date, crawl_date)\n",
    "        else:\n",
    "            actual_date = str(datetime.strptime(text_date, '%d thg %m %Y').date())\n",
    "        actual_date_list.append(actual_date)\n",
    "\n",
    "    lazada_reviews['Rating date'] = actual_date_list\n",
    "\n",
    "    # Loại bỏ những dòng trùng \"Reviewer name\" và \"Content\"\n",
    "    lazada_reviews.drop_duplicates(subset=['Reviewer name', 'Content'], keep='last', inplace=True, ignore_index=True)\n",
    "\n",
    "    # Thêm cột ID của sp\n",
    "    lazada_reviews['ProductID'] = p['ProductID']\n",
    "\n",
    "    # Thêm cột ID của platform\n",
    "    lazada_reviews['PlatformID'] = 'PL01'\n",
    "\n",
    "    # Thêm ID của shop\n",
    "    shop_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Shop.csv')\n",
    "    for shop_name in shop_df['ShopName']:\n",
    "        lazada_reviews.loc[lazada_reviews['Shop name'] == shop_name, 'ShopID'] = shop_df[shop_df['ShopName']==shop_name]['ShopID'].values[0]\n",
    "\n",
    "    add_df = lazada_reviews[['Content', 'ProductID', 'PlatformID', 'Rating date', 'ShopID', 'Rating']].copy()\n",
    "\n",
    "    # Lưu vào file save Market.csv\n",
    "    ecom_reviews_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\EcomReviews.csv')\n",
    "    if len(ecom_reviews_df) == 0:\n",
    "        add_data('EcomReviews.csv', add_df, 'ER00000000')\n",
    "    else:\n",
    "        add_data('EcomReviews.csv', add_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in product_df.to_dict(orient='records'):\n",
    "    product_name = p['ProductName'].lower()\n",
    "    # Kiểm tra file data có tồn tại hay không\n",
    "    file_path = r'..\\Data\\Shopee\\%s_info.csv'%('_'.join(product_name.split(' ')))\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        shopee_product_info = pd.read_csv(file_path)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Tạo lại tên shop\n",
    "    shopee_product_info['ShopID'] = 'ShopeeID_' + shopee_product_info['ShopID'].astype(str)\n",
    "    shopee_product_info.rename(columns = {'ShopID':'Shop Name'}, inplace = True)\n",
    "    shopee_product_info['Shop rating'] = ''\n",
    "    shop_list = shopee_product_info[['Shop Name', 'Shop rating']].copy()\n",
    "    add_shop(shop_list)\n",
    "\n",
    "    # Thêm ID của shop\n",
    "    shop_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Shop.csv')\n",
    "    for shop_name in shop_df['ShopName']:\n",
    "        shopee_product_info.loc[shopee_product_info['Shop Name'] == shop_name, 'ShopID'] = shop_df[shop_df['ShopName']==shop_name]['ShopID'].values[0]\n",
    "\n",
    "    # Price dư 5 số \"0\"\n",
    "    shopee_product_info['Price'] = shopee_product_info['Price'].astype(float) / 100000\n",
    "\n",
    "    # Biến đổi Crawl Date\n",
    "    shopee_product_info['CrawlDate'] = pd.to_datetime(shopee_product_info['CrawlDate'], format=\"%Y-%m-%d %H:%M:%S.%f\").dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Đổi tên cột\n",
    "    shopee_product_info.rename(columns = {'CrawlDate':'Crawl date', 'ReviewCount': 'Reviews count', 'StarRating': 'Star rating'}, inplace = True)\n",
    "\n",
    "    # Kiểm tra thiếu cột giá trị\n",
    "    add_list = ['ProductID', 'PlatformID', 'ShopID', 'Price', 'Quantity', 'Reviews count', 'Star rating', 'Storage', 'Crawl date']\n",
    "    for col in add_list:\n",
    "        if col not in shopee_product_info.columns:\n",
    "            shopee_product_info[col] = np.NaN\n",
    "\n",
    "    add_df = shopee_product_info[add_list].copy()\n",
    "\n",
    "    # Lưu vào file save Market.csv\n",
    "    market_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Market.csv')\n",
    "    if len(market_df) == 0:\n",
    "        add_data('Market.csv', add_df, 'MK000')\n",
    "    else:\n",
    "        add_data('Market.csv', add_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in product_df.to_dict(orient='records'):\n",
    "    product_name = p['ProductName'].lower()\n",
    "    # Kiểm tra file data có tồn tại hay không\n",
    "    file_path = r'..\\Data\\Shopee\\%s_review.csv'%('_'.join(product_name.split(' ')))\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        shopee_reviews = pd.read_csv(file_path)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # Đổi tên shop\n",
    "    shopee_reviews['ShopID'] = 'ShopeeID_' + shopee_reviews['ShopID'].astype(str)\n",
    "    shopee_reviews.rename(columns = {'ShopID':'Shop name'}, inplace = True)\n",
    "\n",
    "    # Thêm ID của shop\n",
    "    shop_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Shop.csv')\n",
    "    for shop_name in shop_df['ShopName']:\n",
    "        shopee_reviews.loc[shopee_reviews['Shop name'] == shop_name, 'ShopID'] = shop_df[shop_df['ShopName']==shop_name]['ShopID'].values[0]\n",
    "\n",
    "    # Đổi tên cột Review thành Content, DateReview thành Rating date, StarRating thành Rating\n",
    "    shopee_reviews.rename(columns = {'DateReview': 'Rating date', 'StarRating':'Rating'}, inplace = True)\n",
    "\n",
    "    add_df = shopee_reviews[['Review', 'ProductID', 'PlatformID', 'Rating date', 'ShopID', 'Rating']].copy()\n",
    "\n",
    "    # Lưu vào file save Market.csv\n",
    "    ecom_reviews_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\EcomReviews.csv')\n",
    "    if len(ecom_reviews_df) == 0:\n",
    "        add_data('EcomReviews.csv', add_df, 'ER00000000')\n",
    "    else:\n",
    "        add_data('EcomReviews.csv', add_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tinhte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
