{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- t·∫°i sao c·ªôt reviewdate c·ªßa pl04 null - xem l·∫°i ti·ªÅn x·ª≠ l√≠ cho c·ªôt reviewdate c·ªßa youtube\n",
    "- 303 d√≤ng null trong c·ªôt review (g·ªìm c·∫£ post v√† comment - pl004 youtube -> samsung)\n",
    "- 236 d√≤ng c·ªßa c·ªôt tilte v√† reviewername,commentcount null (typereview_comment - pl005- tinhte - product 02- samsung)\n",
    "- title youtube: VinhXo , if TITLE.STARTWITH (Vinh X√¥ |) -> remove startwith..\n",
    "- drop duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import dateutil.relativedelta\n",
    "from datetime import date\n",
    "# import pypyodbc as odbc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore',category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drive_name = 'SQL SERVER'\n",
    "# server_name = 'DESKTOP-29355SM\\SQLEXPRESS'\n",
    "# database_name = 'Bank'\n",
    "\n",
    "# connection_string = f\"\"\"\n",
    "#     DRIVER={{{drive_name}}};\n",
    "#     SERVER={server_name};\n",
    "#     DATABASE={database_name};\n",
    "#     Trust_Connection=yes;\n",
    "# \"\"\"\n",
    "\n",
    "# conn = odbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute(\"\"\"\n",
    "# Create table Persons (\n",
    "#     PersonID int,\n",
    "#     LastName varchar(255),\n",
    "#     FirstName varchar(255),\n",
    "#     Address varchar(255),\n",
    "#     City varchar(255)\n",
    "# )\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql('Select * from account', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_review(text_date, crawl_date,key=None): # Bi·∫øn ƒë·ªïi kho·∫£ng th·ªùi gian (1 th√°ng tr∆∞·ªõc, 2 ng√†y tr∆∞·ªõc) th·∫±nh ng√†y c·ª• th·ªÉ v√† tr·∫£ v·ªÅ datetime\n",
    "    sub_text = text_date.split(' ')\n",
    "    date_cmt = ''\n",
    "    if 'nƒÉm' in text_date:\n",
    "        if key is None:\n",
    "            for t in sub_text:\n",
    "                if t.isnumeric():\n",
    "                    date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(years=int(t))\n",
    "        elif key =='tinhte':\n",
    "            for t in sub_text:\n",
    "                if t==\"m·ªôt\":\n",
    "                    date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(years=int(1))\n",
    "                elif t==\"hai\":\n",
    "                    date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(years=int(2))\n",
    "    elif 'th√°ng' in text_date:\n",
    "        for t in sub_text:\n",
    "            if t.isnumeric():\n",
    "                date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(months=int(t))\n",
    "            elif t ==\"m·ªôt\":\n",
    "                date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(months=int(1))\n",
    "    elif 'tu·∫ßn' in text_date:\n",
    "        for t in sub_text:\n",
    "            if t.isnumeric():\n",
    "                date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(weeks==int(t))\n",
    "    elif 'ng√†y' in text_date:\n",
    "        for t in sub_text:\n",
    "            if t.isnumeric():\n",
    "                date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date() - dateutil.relativedelta.relativedelta(days=int(t))\n",
    "    else:\n",
    "        date_cmt = datetime.strptime(crawl_date, '%Y-%m-%d').date()\n",
    "\n",
    "    return date_cmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id(last_id): # T·∫°o ID m·ªõi v√† tr·∫£ v·ªÅ string\n",
    "    last_id_list = []\n",
    "    newest_id = ''\n",
    "\n",
    "    for s in list(last_id):\n",
    "        if s.isnumeric():\n",
    "            last_id_list.append(s)\n",
    "        else:\n",
    "            newest_id += s\n",
    "    \n",
    "    last_id = str(int(''.join(last_id_list)) + 1)\n",
    "    if len(last_id_list) != len(last_id):\n",
    "        num_0 = len(last_id_list) - len(last_id)\n",
    "        newest_id += '0'*num_0 + last_id\n",
    "    else:\n",
    "        newest_id += last_id\n",
    "    \n",
    "    return newest_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data(file_table_name, df, id_format=None): # Th√™m df v√†o file save\n",
    "    # L∆∞u √Ω: df kh√¥ng ch·ª©a c·ªôt ID, th·ª© t·ª± c·ªôt v√† ƒë·ªãnh d·∫°ng gi·ªëng v·ªõi file save v√† n·∫øu file save tr·ªëng th√¨ c·∫ßn ƒë∆∞a ID format (S000, PL00,...)\n",
    "    table = pd.read_csv(r'..\\Data\\Preprocessed_data\\%s'%(file_table_name))\n",
    "\n",
    "    # Lo·∫°i b·ªè nh·ªØng d√≤ng trong df ƒë√£ c√≥ trong table\n",
    "    drop_index = []\n",
    "    for index in range(len(df)):\n",
    "        if list(df.iloc[index]) in table[table.columns[1:]].values.tolist():\n",
    "            drop_index.append(index)\n",
    "    df.drop(drop_index, inplace=True)\n",
    "\n",
    "    newest_id = ''\n",
    "    if id_format != None:\n",
    "        newest_id = create_id(id_format)\n",
    "    else:\n",
    "        newest_id = create_id(table.iloc[-1][0])\n",
    "\n",
    "    list_id = []\n",
    "    for i in range(len(df)):\n",
    "        list_id.append(newest_id)\n",
    "        newest_id = create_id(newest_id)\n",
    "    df.insert(loc=0, column='ID', value=list_id)\n",
    "\n",
    "    df.columns = table.columns\n",
    "    table = pd.concat([table, df], ignore_index=True)\n",
    "    table.to_csv(r'..\\Data\\Preprocessed_data\\%s'%(file_table_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shop(new_shop_df): # Th√™m shop m·ªõi v√†o file Shop.csv (new_shop_df ch·ªâ bao g·ªìm 'Shop name', 'Shop rating' v√† ƒë·∫∑t ƒë√∫ng th·ª© t·ª±)\n",
    "    shop_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\Shop.csv')\n",
    "    check_shop_list = new_shop_df.drop_duplicates(subset=new_shop_df.columns[0], keep='last', ignore_index=True)\n",
    "    drop_index = []\n",
    "\n",
    "    for index_shop in range(len(check_shop_list)):\n",
    "        if check_shop_list.iloc[index_shop][0] in shop_df['ShopName'].values:\n",
    "            drop_index.append(index_shop)\n",
    "\n",
    "    check_shop_list.drop(drop_index, inplace=True)\n",
    "\n",
    "    if len(shop_df) == 0:\n",
    "        add_data('Shop.csv', check_shop_list, id_format='S000')\n",
    "    else:\n",
    "        add_data('Shop.csv', check_shop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product = input()\n",
    "product = 'iphone 15 pro max'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiki_product_info = pd.read_csv(r'..\\Data\\Tiki\\%s_info.csv'%('_'.join(product.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y nh·ªØng c·ªôt c·∫ßn thi·∫øt\n",
    "tiki_product_info = tiki_product_info[['Name', 'Brand', 'Quantity', 'Reviews count', 'Star rating', \n",
    "                                       'Price', 'Crawl date', 'Shop name', 'Shop rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name              object\n",
       "Brand             object\n",
       "Quantity           int64\n",
       "Reviews count      int64\n",
       "Star rating      float64\n",
       "Price             object\n",
       "Crawl date        object\n",
       "Shop name         object\n",
       "Shop rating      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiki_product_info.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th√™m c·ªôt \"Platform ID\"\n",
    "tiki_product_info['Platform ID'] = 'PL01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo·∫°i b·ªè d·∫•u \".\" trong c·ªôt \"Price\" v√† ƒë·ªïi ƒë·ªãnh d·∫°ng th√†nh int\n",
    "tiki_product_info['Price'] = tiki_product_info['Price'].str.replace('.', '', regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Reviews count</th>\n",
       "      <th>Star rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>Crawl date</th>\n",
       "      <th>Shop name</th>\n",
       "      <th>Shop rating</th>\n",
       "      <th>Platform ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple iPhone 15 Pro Max</td>\n",
       "      <td>Apple</td>\n",
       "      <td>691</td>\n",
       "      <td>96</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31990000</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>Tiki Trading</td>\n",
       "      <td>4.7</td>\n",
       "      <td>PL01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple iPhone 15 Pro Max</td>\n",
       "      <td>Apple</td>\n",
       "      <td>726</td>\n",
       "      <td>100</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31990000</td>\n",
       "      <td>2024-01-18</td>\n",
       "      <td>Tiki Trading</td>\n",
       "      <td>4.7</td>\n",
       "      <td>PL01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple iPhone 15 Pro Max</td>\n",
       "      <td>Apple</td>\n",
       "      <td>740</td>\n",
       "      <td>103</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31990000</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "      <td>4.7</td>\n",
       "      <td>PL01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name  Brand  Quantity  Reviews count  Star rating  \\\n",
       "0  Apple iPhone 15 Pro Max  Apple       691             96          5.0   \n",
       "1  Apple iPhone 15 Pro Max  Apple       726            100          5.0   \n",
       "2  Apple iPhone 15 Pro Max  Apple       740            103          5.0   \n",
       "\n",
       "      Price  Crawl date     Shop name  Shop rating Platform ID  \n",
       "0  31990000  2024-01-11  Tiki Trading          4.7        PL01  \n",
       "1  31990000  2024-01-18  Tiki Trading          4.7        PL01  \n",
       "2  31990000  2024-01-27  Tiki Trading          4.7        PL01  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiki_product_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name              object\n",
       "Brand             object\n",
       "Quantity           int64\n",
       "Reviews count      int64\n",
       "Star rating      float64\n",
       "Price              int32\n",
       "Crawl date        object\n",
       "Shop name         object\n",
       "Shop rating      float64\n",
       "Platform ID       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiki_product_info.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiki_reviews = pd.read_csv(r'..\\Data\\Tiki\\%s_reviews.csv'%('_'.join(product.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating date</th>\n",
       "      <th>Crawl date</th>\n",
       "      <th>Shop name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>muasach</td>\n",
       "      <td>22/9 ƒë√∫ng 00h l√™n topzone, TGDƒê, FPT Shop, ƒë·∫∑t...</td>\n",
       "      <td>C·ª±c k√¨ h√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V≈© th·ªã h∆∞·ªùng</td>\n",
       "      <td>ƒêam m√™ t√°o k th·ªÉ b·ªè qua Iphone 15promax v√¨: \\r...</td>\n",
       "      <td>C·ª±c k√¨ h√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B·∫¢O NG√î</td>\n",
       "      <td>[Cu·ªôc g·ªçi l√∫c gi·ªØa ƒë√™m]‚Ä¶\\r\\n\\r\\nKh√¥ng ph·∫£i bon...</td>\n",
       "      <td>C·ª±c k√¨ h√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NG√î QU·ªêC KH√ÅNH</td>\n",
       "      <td>Tiki giao l√∫c 1h s√°ng. √Åp m√£ 500K v√† gi·∫£m 2tr ...</td>\n",
       "      <td>C·ª±c k√¨ h√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hung Trieu</td>\n",
       "      <td>R·∫•t tin t∆∞·ªüng Tiki khi ƒë·∫∑t mua ƒëi·ªán tho·∫°i t·∫°i ...</td>\n",
       "      <td>C·ª±c k√¨ h√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 2 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>vu thang</td>\n",
       "      <td>Th·∫•y b·∫£o nh·∫≠n h√†ng ph·∫£i c√≥ m√£ otp m·ªõi nh·∫≠n ƒëc ...</td>\n",
       "      <td>R·∫•t kh√¥ng h√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 2 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Vi·ªát D≈©ng ƒêo√†n</td>\n",
       "      <td>H√†ng ko cho ƒë·ªïi tr·∫£ khi ƒë·ªïi √Ω</td>\n",
       "      <td>R·∫•t kh√¥ng h√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Thu Nga</td>\n",
       "      <td>Ch∆∞a th·∫•y ho√†n astra cho m√¨nh</td>\n",
       "      <td>Kh√¥ng h√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Nguy·ªÖn Quang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 2 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Tr·∫ßn H√πng ƒê·∫°t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H√†i l√≤ng</td>\n",
       "      <td>ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc</td>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Reviewer name                                            Content  \\\n",
       "0           muasach  22/9 ƒë√∫ng 00h l√™n topzone, TGDƒê, FPT Shop, ƒë·∫∑t...   \n",
       "1      V≈© th·ªã h∆∞·ªùng  ƒêam m√™ t√°o k th·ªÉ b·ªè qua Iphone 15promax v√¨: \\r...   \n",
       "2           B·∫¢O NG√î  [Cu·ªôc g·ªçi l√∫c gi·ªØa ƒë√™m]‚Ä¶\\r\\n\\r\\nKh√¥ng ph·∫£i bon...   \n",
       "3    NG√î QU·ªêC KH√ÅNH  Tiki giao l√∫c 1h s√°ng. √Åp m√£ 500K v√† gi·∫£m 2tr ...   \n",
       "4        Hung Trieu  R·∫•t tin t∆∞·ªüng Tiki khi ƒë·∫∑t mua ƒëi·ªán tho·∫°i t·∫°i ...   \n",
       "..              ...                                                ...   \n",
       "294        vu thang  Th·∫•y b·∫£o nh·∫≠n h√†ng ph·∫£i c√≥ m√£ otp m·ªõi nh·∫≠n ƒëc ...   \n",
       "295  Vi·ªát D≈©ng ƒêo√†n                      H√†ng ko cho ƒë·ªïi tr·∫£ khi ƒë·ªïi √Ω   \n",
       "296         Thu Nga                      Ch∆∞a th·∫•y ho√†n astra cho m√¨nh   \n",
       "297    Nguy·ªÖn Quang                                                NaN   \n",
       "298   Tr·∫ßn H√πng ƒê·∫°t                                                NaN   \n",
       "\n",
       "                 Rating                 Rating date  Crawl date     Shop name  \n",
       "0       C·ª±c k√¨ h√†i l√≤ng  ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc  2024-01-11  Tiki Trading  \n",
       "1       C·ª±c k√¨ h√†i l√≤ng  ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc  2024-01-11  Tiki Trading  \n",
       "2       C·ª±c k√¨ h√†i l√≤ng  ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc  2024-01-11  Tiki Trading  \n",
       "3       C·ª±c k√¨ h√†i l√≤ng  ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc  2024-01-11  Tiki Trading  \n",
       "4       C·ª±c k√¨ h√†i l√≤ng  ƒê√°nh gi√° v√†o 2 th√°ng tr∆∞·ªõc  2024-01-11  Tiki Trading  \n",
       "..                  ...                         ...         ...           ...  \n",
       "294  R·∫•t kh√¥ng h√†i l√≤ng  ƒê√°nh gi√° v√†o 2 th√°ng tr∆∞·ªõc  2024-01-27  Tiki Trading  \n",
       "295  R·∫•t kh√¥ng h√†i l√≤ng  ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc  2024-01-27  Tiki Trading  \n",
       "296      Kh√¥ng h√†i l√≤ng  ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc  2024-01-27  Tiki Trading  \n",
       "297            H√†i l√≤ng  ƒê√°nh gi√° v√†o 2 th√°ng tr∆∞·ªõc  2024-01-27  Tiki Trading  \n",
       "298            H√†i l√≤ng  ƒê√°nh gi√° v√†o 3 th√°ng tr∆∞·ªõc  2024-01-27  Tiki Trading  \n",
       "\n",
       "[299 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiki_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi·∫øn ƒë·ªïi c·ªôt 'Rating date' th√†nh ng√†y c·ª• th·ªÉ th√¥ng qua 'Crawl date'\n",
    "actual_date_list = []\n",
    "\n",
    "for num in range(len(tiki_reviews)):\n",
    "    text_date = tiki_reviews.loc[num, ['Rating date', 'Crawl date']][0]\n",
    "    crawl_date = tiki_reviews.loc[num, ['Rating date', 'Crawl date']][1]\n",
    "\n",
    "    actual_date = extract_date_review(text_date, crawl_date)\n",
    "    actual_date_list.append(actual_date)\n",
    "\n",
    "tiki_reviews['Rating date'] = actual_date_list\n",
    "tiki_reviews.drop(columns=['Crawl date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi·∫øn ƒë·ªïi c·ªôt \"Rating\" th√†nh thang ƒëo likert\n",
    "rating_likert = {'R·∫•t kh√¥ng h√†i l√≤ng': 1, 'Kh√¥ng h√†i l√≤ng': 2, 'B√¨nh th∆∞·ªùng': 3, 'H√†i l√≤ng': 4, 'C·ª±c k√¨ h√†i l√≤ng': 5}\n",
    "\n",
    "for num in range(len(tiki_reviews)):\n",
    "    rating = tiki_reviews.loc[num, 'Rating']\n",
    "    for k, v in rating_likert.items():\n",
    "        if rating == k:\n",
    "            tiki_reviews.loc[num, 'Rating'] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo·∫°i b·ªè nh·ªØng d√≤ng tr√πng \"Reviewer name\" v√† \"Content\"\n",
    "tiki_reviews.drop_duplicates(subset=['Reviewer name', 'Content'], keep='last', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Rating date</th>\n",
       "      <th>Shop name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L√Ω Nguyen</td>\n",
       "      <td>üòÇ. Haha</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vu thang</td>\n",
       "      <td>Th·∫•y b·∫£o nh·∫≠n h√†ng ph·∫£i c√≥ m√£ otp m·ªõi nh·∫≠n ƒëc ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-11</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muasach</td>\n",
       "      <td>22/9 ƒë√∫ng 00h l√™n topzone, TGDƒê, FPT Shop, ƒë·∫∑t...</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V≈© th·ªã h∆∞·ªùng</td>\n",
       "      <td>ƒêam m√™ t√°o k th·ªÉ b·ªè qua Iphone 15promax v√¨: \\r...</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B·∫¢O NG√î</td>\n",
       "      <td>[Cu·ªôc g·ªçi l√∫c gi·ªØa ƒë√™m]‚Ä¶\\r\\n\\r\\nKh√¥ng ph·∫£i bon...</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>vu thang</td>\n",
       "      <td>Th·∫•y b·∫£o nh·∫≠n h√†ng ph·∫£i c√≥ m√£ otp m·ªõi nh·∫≠n ƒëc ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Vi·ªát D≈©ng ƒêo√†n</td>\n",
       "      <td>H√†ng ko cho ƒë·ªïi tr·∫£ khi ƒë·ªïi √Ω</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Thu Nga</td>\n",
       "      <td>Ch∆∞a th·∫•y ho√†n astra cho m√¨nh</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Nguy·ªÖn Quang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Tr·∫ßn H√πng ƒê·∫°t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-10-27</td>\n",
       "      <td>Tiki Trading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Reviewer name                                            Content Rating  \\\n",
       "0        L√Ω Nguyen                                             üòÇ. Haha      5   \n",
       "1          vu thang  Th·∫•y b·∫£o nh·∫≠n h√†ng ph·∫£i c√≥ m√£ otp m·ªõi nh·∫≠n ƒëc ...      1   \n",
       "2           muasach  22/9 ƒë√∫ng 00h l√™n topzone, TGDƒê, FPT Shop, ƒë·∫∑t...      5   \n",
       "3      V≈© th·ªã h∆∞·ªùng  ƒêam m√™ t√°o k th·ªÉ b·ªè qua Iphone 15promax v√¨: \\r...      5   \n",
       "4           B·∫¢O NG√î  [Cu·ªôc g·ªçi l√∫c gi·ªØa ƒë√™m]‚Ä¶\\r\\n\\r\\nKh√¥ng ph·∫£i bon...      5   \n",
       "..              ...                                                ...    ...   \n",
       "96         vu thang  Th·∫•y b·∫£o nh·∫≠n h√†ng ph·∫£i c√≥ m√£ otp m·ªõi nh·∫≠n ƒëc ...      1   \n",
       "97   Vi·ªát D≈©ng ƒêo√†n                      H√†ng ko cho ƒë·ªïi tr·∫£ khi ƒë·ªïi √Ω      1   \n",
       "98          Thu Nga                      Ch∆∞a th·∫•y ho√†n astra cho m√¨nh      2   \n",
       "99     Nguy·ªÖn Quang                                                NaN      4   \n",
       "100   Tr·∫ßn H√πng ƒê·∫°t                                                NaN      4   \n",
       "\n",
       "    Rating date     Shop name  \n",
       "0    2023-12-23  Tiki Trading  \n",
       "1    2023-12-11  Tiki Trading  \n",
       "2    2023-09-27  Tiki Trading  \n",
       "3    2023-09-27  Tiki Trading  \n",
       "4    2023-09-27  Tiki Trading  \n",
       "..          ...           ...  \n",
       "96   2023-11-27  Tiki Trading  \n",
       "97   2023-10-27  Tiki Trading  \n",
       "98   2023-10-27  Tiki Trading  \n",
       "99   2023-11-27  Tiki Trading  \n",
       "100  2023-10-27  Tiki Trading  \n",
       "\n",
       "[101 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiki_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function\n",
    "def fill_nan_values(df,key): \n",
    "    # Fill NaN when combined comment and post data\n",
    "    url_groups = df.groupby(key)\n",
    "    for _,group in url_groups:\n",
    "        non_nan_row = group.dropna(subset=['Title','ReviewerName','CommentCount'])\n",
    "        if non_nan_row.empty:\n",
    "            continue\n",
    "        non_nan_row = non_nan_row.iloc[0]\n",
    "        nan_rows_index = group.index[group[['Title','ReviewerName','CommentCount']].isnull().any(axis=1)].tolist()\n",
    "        for index in nan_rows_index:\n",
    "            df.loc[index,'Title']  =non_nan_row['Title']\n",
    "            df.loc[index,'ReviewerName'] = non_nan_row['ReviewerName']\n",
    "            df.loc[index,'CommentCount'] = non_nan_row['CommentCount']\n",
    "            if key=='Id':\n",
    "                df.loc[index,'ViewCount'] = non_nan_row['ViewCount']\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tinhte _Uncompleted\n",
    " -- Handing NaN values: finding causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to remove non content pages (page2, page3...) -- for post data OR edit link (xx/page2;xx/page3 -> xx/) -- for comment data\n",
    "def remove_or_edit_links(data,type):\n",
    "    if type.lower() == 'post':\n",
    "        del_rows=0\n",
    "        for index,link in data['Link'].items():\n",
    "            last_link = link.split('/')[-1]\n",
    "            if last_link !='':\n",
    "                data.drop(index,inplace=True)\n",
    "                del_rows+=1\n",
    "        print(f'Deleted: {del_rows} rows')\n",
    "\n",
    "    elif type.lower() =='cmt' or type.lower()=='comment':\n",
    "        edited_rows=0\n",
    "        for index,link in data['Link'].items():\n",
    "            last_link =  link.split('/')\n",
    "            if last_link[-1] !='':\n",
    "                del(last_link[-1])\n",
    "                newlink = '/'.join(last_link) +'/'\n",
    "                data['Link'].iloc[index] = newlink\n",
    "                edited_rows+=1\n",
    "\n",
    "        print(f'Edited: {edited_rows} links')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: 0 rows\n",
      "Edited: 0 links\n",
      "Deleted: 24 rows\n",
      "Edited: 626 links\n",
      "Review             26\n",
      "ProductID           0\n",
      "PlatformID          0\n",
      "TypeReview          0\n",
      "DateReview          0\n",
      "Title             235\n",
      "ReviewerName      235\n",
      "ViewCount       15326\n",
      "CommentCount      235\n",
      "dtype: int64\n",
      "Number rows inserted: 15326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# provide keyword items folowing index[Nameproduct,Product_id,crawldate]\n",
    "tt_keyword = [['Iphone15pm','P001'],['SamsungS23u','P002']]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(tt_keyword)):\n",
    "    \n",
    "    name_info= pd.read_csv(f'..\\Data\\TinhTe\\TinhTe_{tt_keyword[i][0]}_InfoPosts.csv')\n",
    "    name_cmt = pd.read_csv(f'..\\Data\\TinhTe\\TinhTe_{tt_keyword[i][0]}_Comments.csv')\n",
    "\n",
    "    # Convert Date columns to the same format: %Y-%m-%d\n",
    "    name_info['Post Date'] = pd.to_datetime(name_info['Post Date'],format='%d/%m/%Y %H:%M')\n",
    "    name_info['Post Date'] = name_info['Post Date'].dt.strftime('%Y-%m-%d')\n",
    "    name_cmt['Crawl date'] = date(2024,1,19).strftime('%Y-%m-%d')\n",
    "\n",
    "    actual_date_list = []\n",
    "\n",
    "    for num in range(len(name_cmt)):\n",
    "        text_date = name_cmt.loc[num, ['Date', 'Crawl date']][0]\n",
    "        crawl_date = name_cmt.loc[num, ['Date', 'Crawl date']][1]\n",
    "        actual_date = extract_date_review(text_date, crawl_date,'tinhte')\n",
    "        actual_date_list.append(actual_date)\n",
    "\n",
    "    name_cmt['Date'] = actual_date_list\n",
    "    name_cmt.drop(columns=['Crawl date'],inplace=True)\n",
    "\n",
    "    # Link Column \n",
    "    name_info = remove_or_edit_links(name_info,'post')\n",
    "    name_cmt = remove_or_edit_links(name_cmt,'cmt')\n",
    "\n",
    "    # Rename columns following the required format in the Database\n",
    "    name_info.rename(columns={'Author':'ReviewerName','Post Date':'DateReview','Comments Count':'CommentCount','Content':'Review'},inplace=True)\n",
    "    name_cmt.rename(columns={'Date':'DateReview','Comment':'Review'},inplace=True)\n",
    "\n",
    "    # Add PlatformID column\n",
    "    name_info['PlatformID'] = 'PL05'\n",
    "    name_cmt['PlatformID'] = 'PL05'\n",
    "\n",
    "    # Add ProductID column\n",
    "    name_info['ProductID'] = tt_keyword[i][1]\n",
    "    name_cmt['ProductID'] = tt_keyword[i][1]\n",
    "\n",
    "    # Add TypeReview column\n",
    "    name_info['TypeReview'] = 'Post'\n",
    "    name_cmt['TypeReview'] = 'Comment'\n",
    "    \n",
    "    # Preprocess date column of samsung comment  data again\n",
    "    name_info['DateReview'] = pd.to_datetime(name_info['DateReview']) \n",
    "    name_cmt['DateReview'] = pd.to_datetime(name_cmt['DateReview']) \n",
    "\n",
    "    # Add data to df - summary file\n",
    "    df = pd.concat([df,name_info,name_cmt],ignore_index=True)\n",
    "\n",
    "df = fill_nan_values(df,'Link')\n",
    "\n",
    "#Drop unneccesary columns\n",
    "df.drop(columns=['Link'], inplace=True)\n",
    "df['ViewCount'] = None\n",
    "desired_columns=['Review', 'ProductID', 'PlatformID', 'TypeReview',\n",
    "                'DateReview', 'Title', 'ReviewerName', 'ViewCount', 'CommentCount']\n",
    "df=df[desired_columns]\n",
    "\n",
    "# Check data\n",
    "df['DateReview'] = pd.to_datetime(df['DateReview']) \n",
    "df['ViewCount'] = df['ViewCount'].astype(float)  \n",
    "df['CommentCount'] = df['CommentCount'].astype(float)\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Save data\n",
    "smr_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\SocialMediaReviews.csv')\n",
    "print('Number rows inserted:',len(df))\n",
    "if len(smr_df) == 0:\n",
    "    add_data('SocialMediaReviews.csv', df, 'SM00000000')\n",
    "else:\n",
    "    add_data('SocialMediaReviews.csv', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube -- reply comments preprocessing\n",
    "- reply comments\n",
    "- convert comment(cmt) , date published(info) to the general format\n",
    "- group comment id to fill null values in comment data (cmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_keyword = [['iphone_15_pro_max','P001'],['galaxy_s23_ultra','P002']]\n",
    "\n",
    "# A function to preprocess and remove usertag in reply comment column\n",
    "def reply_comments(yt_cmt,name_data):\n",
    "    count=0\n",
    "    print(f'Initial {name_data} comment data include: {len(yt_cmt)} rows')\n",
    "    for index,reply in  yt_cmt['Reply'].items():\n",
    "        if reply is not None and not isinstance(reply, float) and not isinstance(reply, int):\n",
    "            reply = reply.split('<>')\n",
    "            for rl in reply:\n",
    "                # Remove tag user: @@name_user\n",
    "                if rl.startswith(\"@@\"):\n",
    "                    lst_rl = rl.split()\n",
    "                    rl = ' '.join(lst_rl[1:])\n",
    "                count+=1\n",
    "                new_row_df = {'Unnamed: 0':None,'Id':yt_cmt.loc[index,'Id'],'Comment':rl,'Comment time':yt_cmt.loc[index,'Comment time'],'Reply':None}\n",
    "                yt_cmt.loc[len(yt_cmt)] = new_row_df\n",
    "    print('Number rows inserted:',count)\n",
    "    print(f'After preprocessing [Reply] column, {name_data} comment data include: {len(yt_cmt)} rows')\n",
    "    return yt_cmt\n",
    "\n",
    "def yt_preprocessing():\n",
    "    yt_df = pd.DataFrame()\n",
    "    for i in range(len(yt_keyword)):\n",
    "\n",
    "        #Import data\n",
    "        yt_info = pd.read_csv(f'../Data/Youtube/video_info_{yt_keyword[i][0]}.csv')\n",
    "        yt_cmt = pd.read_csv(f'../Data/Youtube/comments_{yt_keyword[i][0]}.csv')\n",
    "        \n",
    "        # Preprocessing reply cmts\n",
    "        yt_cmt = reply_comments(yt_cmt,yt_keyword[i][0])\n",
    "        \n",
    "        # Rename columns\n",
    "        yt_info.rename(columns={'Date published':'DateReview','Channel title':'ReviewerName',\n",
    "                                'Comments count':'CommentCount','View count':'ViewCount'},inplace=True)\n",
    "        yt_cmt.rename(columns={'Comment':'Review','Comment time':'DateReview'},inplace=True)\n",
    "\n",
    "        # Add ProductID column\n",
    "        yt_info['ProductID'] = yt_keyword[i][1]\n",
    "        yt_cmt['ProductID'] = yt_keyword[i][1]\n",
    "\n",
    "        # Add TypeReview column\n",
    "        yt_info['TypeReview'] = 'Post'\n",
    "        yt_cmt['TypeReview'] = 'Comment'\n",
    "        # Add data to main df\n",
    "        yt_df = pd.concat([yt_df,yt_info,yt_cmt],ignore_index=True)\n",
    "\n",
    "    return yt_df\n",
    "\n",
    "\n",
    "def yt_main(df):\n",
    "    df = fill_nan_values(df,'Id')\n",
    "    # Remove unneccesary columns\n",
    "    df.drop(columns=['Unnamed: 0','Like count','Id'],inplace=True)\n",
    "    # Add PlatformID column \n",
    "    df['PlatformID'] ='PL04'\n",
    "    # Convert DateReview column to the general format\n",
    "    df['DateReview'] = pd.to_datetime(df['DateReview'],format=\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    df['DateReview'] = df['DateReview'].dt.strftime('%Y-%m-%d')\n",
    "    df['ViewCount'] = df['ViewCount'].astype(float) \n",
    "    df['CommentCount'] = df['CommentCount'].astype(float)\n",
    "    print('-----------------------------------------------------')\n",
    "    print('Check number of null rows /columns in dataframe: ')\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial iphone_15_pro_max comment data include: 15233 rows\n",
      "Number rows inserted: 9289\n",
      "After preprocessing [Reply] column, iphone_15_pro_max comment data include: 24522 rows\n",
      "Initial galaxy_s23_ultra comment data include: 11429 rows\n",
      "Number rows inserted: 9264\n",
      "After preprocessing [Reply] column, galaxy_s23_ultra comment data include: 20693 rows\n",
      "-----------------------------------------------------\n",
      "Check number of null rows /columns in dataframe: \n",
      "DateReview          0\n",
      "Title               0\n",
      "ReviewerName        0\n",
      "ViewCount           0\n",
      "CommentCount        0\n",
      "ProductID           0\n",
      "TypeReview          0\n",
      "Review            255\n",
      "Reply           37542\n",
      "PlatformID          0\n",
      "dtype: int64\n",
      "After all preprocessing basic steps, Youtube data include 45466 rows.\n",
      "Index(['Review', 'ProductID', 'PlatformID', 'TypeReview', 'DateReview',\n",
      "       'Title', 'ReviewerName', 'ViewCount', 'CommentCount'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nguye\\AppData\\Local\\Temp\\ipykernel_18072\\3735578254.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(drop_index, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "pre_df= yt_preprocessing()\n",
    "yt_df = yt_main(pre_df)\n",
    "\n",
    "# Save file\n",
    "desired_columns=['Review', 'ProductID', 'PlatformID', 'TypeReview',\n",
    "                'DateReview', 'Title', 'ReviewerName', 'ViewCount', 'CommentCount']\n",
    "yt_df=yt_df[desired_columns]\n",
    "print(f'After all preprocessing basic steps, Youtube data include {len(yt_df)} rows.')\n",
    "print(yt_df.columns)\n",
    "smr_df = pd.read_csv(r'..\\Data\\Preprocessed_data\\SocialMediaReviews.csv')\n",
    "if len(smr_df) == 0:\n",
    "    add_data('SocialMediaReviews.csv', yt_df, 'SM00000000')\n",
    "else:\n",
    "    add_data('SocialMediaReviews.csv', yt_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check len() of socialmediareviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMReviewID          0\n",
      "Review            302\n",
      "ProductID           0\n",
      "PlatformID          0\n",
      "TypeReview          0\n",
      "DateReview          0\n",
      "Title             235\n",
      "ReviewerName      235\n",
      "ViewCount       15326\n",
      "CommentCount      235\n",
      "dtype: int64\n",
      "60792\n"
     ]
    }
   ],
   "source": [
    "df_smm = pd.read_csv('../Data/Preprocessed_data/SocialMediaReviews.csv')\n",
    "print(df_smm.isna().sum())\n",
    "print(len(df_smm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset data saved\n",
    "df_smm = pd.read_csv('../Data/Preprocessed_data/SocialMediaReviews.csv')\n",
    "print(df_smm.isna().sum())\n",
    "columns = df_smm.columns\n",
    "\n",
    "empty_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Save the empty DataFrame back to the CSV file, overwriting it\n",
    "empty_df.to_csv('../Data/Preprocessed_data/SocialMediaReviews.csv', index=False)\n",
    "\n",
    "print(\"Data removed from the CSV file, only column headers remain.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
